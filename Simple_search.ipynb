{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following along with [80 Line Search Engine](https://www.alexmolas.com/2024/02/05/a-search-engine-in-80-lines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open complete csv\n",
    "complete = pd.read_csv('../StarTrekNextGenScriptData/complete_data.csv')\n",
    "complete.columns = ['index', 'character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Search Engine Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to use  --- may wanna update this to lemmatize\n",
    "def normalize_string(input_string: str) -> str:\n",
    "    translation_table = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    string_without_punc = input_string.translate(translation_table)\n",
    "    string_without_double_spaces = ' '.join(string_without_punc.split())\n",
    "    return string_without_double_spaces.lower()\n",
    "\n",
    "def update_url_scores(old: dict[str, float], new: dict[str, float]):\n",
    "    for url, score in new.items():\n",
    "        if url in old:\n",
    "            old[url] += score\n",
    "        else:\n",
    "            old[url] = score\n",
    "    return old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    '''Search engine class'''\n",
    "    def __init__(self, index:dict[str, dict[str, int]]=None, docs: dict[str, str]=None,k1:float=1.5,b:float=0.75,name:str='Default Search Engine'):\n",
    "        '''Instantiate the search engine class.\n",
    "        Input:\n",
    "            index: dict[str, dict[int,int]], the inverted index\n",
    "            docs: dict[int, str], key is the id of the quote and value is the quote text\n",
    "            k1: float, k1 constant to use for bm25\n",
    "            b: float, b constant to use for bm25\n",
    "        Output:\n",
    "            None, class instantiation\n",
    "        '''\n",
    "        if index is None:\n",
    "            self.index = defaultdict(lambda: defaultdict(int))\n",
    "        else:\n",
    "            self.index = index\n",
    "        if docs is None:\n",
    "            self.docs = {}\n",
    "        else:\n",
    "            self.docs = docs\n",
    "        self.k1 =k1\n",
    "        self.b = b\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self)->str:\n",
    "        '''Print readable name of the search engine\n",
    "        Output:\n",
    "            str: name of the instance\n",
    "        '''\n",
    "        return(self.name)\n",
    "\n",
    "    def bulk_load(self,data:dict)->None:\n",
    "        '''Bulk loads new documents to add to the search engine.\n",
    "\n",
    "        Input:\n",
    "            data: dict[int,str], where int is the id and str is the content\n",
    "        '''\n",
    "        original_len = len(self.docs.keys())\n",
    "        for ind in data.keys():\n",
    "            # get the content & the id\n",
    "            content = data[ind]\n",
    "            id = ind\n",
    "            # add to doc list\n",
    "            self.docs[id]=normalize_string(content)\n",
    "            # normalize content\n",
    "            words = normalize_string(content).split(\" \")\n",
    "            # update the index\n",
    "            for word in words:\n",
    "                self.index[word][id] += 1\n",
    "        new_len =original_len = len(self.docs.keys())\n",
    "        print(f'We have added {new_len-original_len} documents. The engine now has {new_len} documents.')\n",
    "\n",
    "    def load(self,document:str)->None:\n",
    "        '''Load a single document into the search engine. Ideally this should not be used.\n",
    "\n",
    "        Input:\n",
    "            document: str, the new text document to add to the search engine.\n",
    "        '''\n",
    "        new_id = len(self.docs.keys())\n",
    "        self.docs[new_id]=normalize_string(document)\n",
    "        words = normalize_string(document).split(\" \")\n",
    "        for word in words:\n",
    "            self.index[word][new_id]\n",
    "\n",
    "    def num_docs(self)->int:\n",
    "        '''Returns the number of docs\n",
    "\n",
    "        Output:\n",
    "            int: length of docs\n",
    "        '''\n",
    "        return len(self.docs.keys())\n",
    "\n",
    "    def find_ids(self,keyword:string)->dict:\n",
    "        keyword =normalize_string(keyword)\n",
    "        return self.index[keyword]\n",
    "\n",
    "    def bw_idf(self,keyword:str)->float:\n",
    "    # for each term, get the idf\n",
    "        num_docs = self.num_docs()\n",
    "        n_kw = len(self.find_ids(keyword))\n",
    "        return log((num_docs-n_kw+0.5)/(n_kw+0.5)+1)\n",
    "    \n",
    "    def bm25(self, keyword:str)-> dict[str, float]:\n",
    "        result = {}\n",
    "        idf = self.bw_idf(keyword)\n",
    "        avg_ql = sum(len(d) for d in self.docs.values()) / len(self.docs)\n",
    "        for id, freq in self.find_ids(keyword).items():\n",
    "            num = freq * (self.k1+1)\n",
    "            denom = freq+self.k1*(1 - self.b + self.b * len(self.docs[id]) / avg_ql)\n",
    "            result[id]=idf * num /denom\n",
    "        return result\n",
    "    \n",
    "    def bw_search(self,query:str,limit:int=None)->dict[str,float]:\n",
    "        kws = normalize_string(query).split(\" \")\n",
    "        scores ={} # dict[str, float] \n",
    "        for k in kws:\n",
    "            kw_url_score = self.bm25(k)\n",
    "            scores = update_url_scores(scores,kw_url_score)\n",
    "        sort_scores = sorted(scores.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "        if limit is not None:\n",
    "            sort_scores = sort_scores[:limit]\n",
    "        return sort_scores\n",
    "    \n",
    "    def pretty_print(self,ids:list)->list:\n",
    "        '''Prints the quotes instead of a list of ids'''\n",
    "        # get context\n",
    "        output = []\n",
    "        for x in ids:\n",
    "            context = [self.docs[x-1],self.docs[x],self.docs[x+1]]\n",
    "            output.append(context)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 0 documents. The engine now has 144211 documents.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144211"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_engine = search_engine()\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])\n",
    "test_engine.num_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['who s there show yourself', 'quark quark', 'tarkalean tea'],\n",
       " ['we were told you have games',\n",
       "  'quark s take us to quark s',\n",
       "  'right this way'],\n",
       " ['then go ahead and shoot',\n",
       "  'quark quark are you all right',\n",
       "  'still doesn t believe it you shot me'],\n",
       " ['on screen', 'quark', 'i see you remember me'],\n",
       " ['why do i bother', 'quark', 'what can i do for you constable'],\n",
       " ['this is all very amusing but i can t start a bar with a case of bad brandy and a set of ugly glasses',\n",
       "  'quark',\n",
       "  'yes captain'],\n",
       " ['it s not charity i find this undrinkable now do you want it or should i dump it',\n",
       "  'quark',\n",
       "  'my sister sent me these i thought you might want them they re really ugly'],\n",
       " ['you bet it does', 'quark', 'where s your luggage'],\n",
       " ['quark', 'quark', 'what do you want'],\n",
       " ['and it s all yours', 'quark', 'quark'],\n",
       " ['continuing yelling out again we have nothing to do with her this is a misunderstanding',\n",
       "  'quark',\n",
       "  'i have the right to express my opinion'],\n",
       " ['me neither but it was very good commander i think i m developing a taste for human food',\n",
       "  'quark',\n",
       "  'i still say some dirt got into the sauce and these bugs look at this he picks a tiny speck out of his food they get into everything it s disgusting'],\n",
       " ['just another minute', 'quark', 'look chief i m a little busy right'],\n",
       " ['my quarters are right below his you wouldn t believe the racket he makes',\n",
       "  'quark',\n",
       "  'do you know what it s like to hear someone practice shape shifting last night it sounded like a takaran wildebeest was tromping around up there'],\n",
       " ['right nobody moves except you now open the cells',\n",
       "  'quark',\n",
       "  'still looking at the bodies yes'],\n",
       " ['coming moogie',\n",
       "  'quark',\n",
       "  'sisko to all ships cruiser and galaxy wings drop to half impulse you too dax'],\n",
       " ['mother', 'quark', 'moogie'],\n",
       " ['they re disgusting hairy little creatures with ravenous appetites and i want them gone',\n",
       "  'quark',\n",
       "  'i know i know this is just a temporary setback the bar will open again and i can get back to my life'],\n",
       " ['no it s exactly the time i think i know where you can find kira you see odo blackmailed me into helping him a matter i ve been meaning to bring to your attention commander',\n",
       "  'quark',\n",
       "  'i managed to find out where the circle s headquarters is in the labyrinths beneath the perikian peninsula'],\n",
       " ['the best and the brightest', 'quark', 'you re serious about it']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_results = test_engine.bw_search('Quark',20)\n",
    "# sorted_items = sorted(q_results.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "# sorted_items\n",
    "test_engine.pretty_print([x[0] for x in q_results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si649f23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
