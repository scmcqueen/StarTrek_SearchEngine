{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following along with [80 Line Search Engine](https://www.alexmolas.com/2024/02/05/a-search-engine-in-80-lines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open complete csv\n",
    "complete = pd.read_csv('../StarTrekNextGenScriptData/complete_data.csv')\n",
    "complete.columns = ['index', 'character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Search Engine Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to use  --- may wanna update this to lemmatize\n",
    "def normalize_string(input_string: str) -> str:\n",
    "    translation_table = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    string_without_punc = input_string.translate(translation_table)\n",
    "    string_without_double_spaces = ' '.join(string_without_punc.split())\n",
    "    return string_without_double_spaces.lower()\n",
    "\n",
    "def update_url_scores(old: dict[str, float], new: dict[str, float]):\n",
    "    for url, score in new.items():\n",
    "        if url in old:\n",
    "            old[url] += score\n",
    "        else:\n",
    "            old[url] = score\n",
    "    return old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    '''Search engine class'''\n",
    "    def __init__(self, index:dict[str, dict[str, int]]=None, docs: dict[str, str]=None,k1:float=1.5,b:float=0.75,name:str='Default Search Engine'):\n",
    "        '''Instantiate the search engine class.\n",
    "        Input:\n",
    "            index: dict[str, dict[int,int]], the inverted index\n",
    "            docs: dict[int, str], key is the id of the quote and value is the quote text\n",
    "            k1: float, k1 constant to use for bm25\n",
    "            b: float, b constant to use for bm25\n",
    "        Output:\n",
    "            None, class instantiation\n",
    "        '''\n",
    "        if index is None:\n",
    "            self.index = defaultdict(lambda: defaultdict(int))\n",
    "        else:\n",
    "            self.index = index\n",
    "        if docs is None:\n",
    "            self.docs = {}\n",
    "        else:\n",
    "            self.docs = docs\n",
    "        self.k1 =k1\n",
    "        self.b = b\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self)->str:\n",
    "        '''Print readable name of the search engine\n",
    "        Output:\n",
    "            str: name of the instance\n",
    "        '''\n",
    "        return(self.name)\n",
    "\n",
    "    def bulk_load(self,data:dict)->None:\n",
    "        '''Bulk loads new documents to add to the search engine.\n",
    "\n",
    "        Input:\n",
    "            data: dict[int,str], where int is the id and str is the content\n",
    "        '''\n",
    "        original_len = len(self.docs.keys())\n",
    "        for ind in data.keys():\n",
    "            # get the content & the id\n",
    "            content = data[ind]\n",
    "            id = ind\n",
    "            # add to doc list\n",
    "            self.docs[id]=normalize_string(content)\n",
    "            # normalize content\n",
    "            words = normalize_string(content).split(\" \")\n",
    "            # update the index\n",
    "            for word in words:\n",
    "                self.index[word][id] += 1\n",
    "        new_len =original_len = len(self.docs.keys())\n",
    "        print(f'We have added {new_len-original_len} documents. The engine now has {new_len} documents.')\n",
    "\n",
    "    def load(self,document:str)->None:\n",
    "        '''Load a single document into the search engine. Ideally this should not be used.\n",
    "\n",
    "        Input:\n",
    "            document: str, the new text document to add to the search engine.\n",
    "        '''\n",
    "        new_id = len(self.docs.keys())\n",
    "        self.docs[new_id]=normalize_string(document)\n",
    "        words = normalize_string(document).split(\" \")\n",
    "        for word in words:\n",
    "            self.index[word][new_id]\n",
    "\n",
    "    def num_docs(self)->int:\n",
    "        '''Returns the number of docs\n",
    "\n",
    "        Output:\n",
    "            int: length of docs\n",
    "        '''\n",
    "        return len(self.docs.keys())\n",
    "\n",
    "    def find_ids(self,keyword:string)->dict:\n",
    "        keyword =normalize_string(keyword)\n",
    "        return self.index[keyword]\n",
    "\n",
    "    def bw_idf(self,keyword:str)->float:\n",
    "    # for each term, get the idf\n",
    "        num_docs = self.num_docs()\n",
    "        n_kw = len(self.find_ids(keyword))\n",
    "        return log((num_docs-n_kw+0.5)/(n_kw+0.5)+1)\n",
    "    \n",
    "    def bm25(self, keyword:str)-> dict[str, float]:\n",
    "        result = {}\n",
    "        idf = self.bw_idf(keyword)\n",
    "        avg_ql = sum(len(d) for d in self.docs.values()) / len(self.docs)\n",
    "        for id, freq in self.find_ids(keyword).items():\n",
    "            num = freq * (self.k1+1)\n",
    "            denom = freq+self.k1*(1 - self.b + self.b * len(self.docs[id]) / avg_ql)\n",
    "            result[id]=idf * num /denom\n",
    "        return result\n",
    "    \n",
    "    def bw_search(self,query:str,limit:int=None)->dict[str,float]:\n",
    "        kws = normalize_string(query).split(\" \")\n",
    "        scores ={} # dict[str, float] \n",
    "        for k in kws:\n",
    "            kw_url_score = self.bm25(k)\n",
    "            scores = update_url_scores(scores,kw_url_score)\n",
    "        sort_scores = sorted(scores.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "        if limit is not None:\n",
    "            sort_scores = sort_scores[:limit]\n",
    "        return sort_scores\n",
    "    \n",
    "    def pretty_print(self,ids:list)->list:\n",
    "        '''Prints the quotes instead of a list of ids'''\n",
    "        return([self.docs[x] for x in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 0 documents. The engine now has 144211 documents.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144211"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_engine = search_engine()\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])\n",
    "test_engine.num_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quark quark',\n",
       " 'quark s take us to quark s',\n",
       " 'quark quark are you all right',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark',\n",
       " 'quark']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_results = test_engine.bw_search('Quark',20)\n",
    "# sorted_items = sorted(q_results.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "# sorted_items\n",
    "test_engine.pretty_print([x[0] for x in q_results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si649f23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
