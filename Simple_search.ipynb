{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following along with [80 Line Search Engine](https://www.alexmolas.com/2024/02/05/a-search-engine-in-80-lines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open complete csv\n",
    "complete = pd.read_csv('../StarTrekNextGenScriptData/complete_data.csv')\n",
    "complete.columns = ['index', 'character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Search Engine Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to use  --- may wanna update this to lemmatize\n",
    "def normalize_string(input_string: str) -> str:\n",
    "    translation_table = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    string_without_punc = input_string.translate(translation_table)\n",
    "    string_without_double_spaces = ' '.join(string_without_punc.split())\n",
    "    return string_without_double_spaces.lower()\n",
    "\n",
    "def update_url_scores(old: dict[str, float], new: dict[str, float]):\n",
    "    for url, score in new.items():\n",
    "        if url in old:\n",
    "            old[url] += score\n",
    "        else:\n",
    "            old[url] = score\n",
    "    return old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    '''Search engine class'''\n",
    "    def __init__(self, index:dict[str, dict[str, int]]=None, docs: dict[str, str]=None,original_docs: dict[str, str]=None,k1:float=1.5,b:float=0.75,name:str='Default Search Engine'):\n",
    "        '''Instantiate the search engine class.\n",
    "        Input:\n",
    "            index: dict[str, dict[int,int]], the inverted index\n",
    "            docs: dict[int, str], key is the id of the quote and value is the quote text\n",
    "            k1: float, k1 constant to use for bm25\n",
    "            b: float, b constant to use for bm25\n",
    "        Output:\n",
    "            None, class instantiation\n",
    "        '''\n",
    "        if index is None:\n",
    "            self.index = defaultdict(lambda: defaultdict(int))\n",
    "        else:\n",
    "            self.index = index\n",
    "        if docs is None:\n",
    "            self.docs = {}\n",
    "        else:\n",
    "            self.docs = docs\n",
    "        if original_docs is None:\n",
    "            self.original_docs = {}\n",
    "        else:\n",
    "            self.original_docs = original_docs\n",
    "        self.k1 =k1\n",
    "        self.b = b\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self)->str:\n",
    "        '''Print readable name of the search engine\n",
    "        Output:\n",
    "            str: name of the instance\n",
    "        '''\n",
    "        return(self.name)\n",
    "\n",
    "    def bulk_load(self,data:dict)->None:\n",
    "        '''Bulk loads new documents to add to the search engine.\n",
    "\n",
    "        Input:\n",
    "            data: dict[int,str], where int is the id and str is the content\n",
    "        '''\n",
    "        original_len = len(self.docs.keys())\n",
    "        for ind in data.keys():\n",
    "            # get the content & the id\n",
    "            content = data[ind]\n",
    "            id = ind\n",
    "            # add original docs\n",
    "            self.original_docs[id]=content\n",
    "            # add to doc list\n",
    "            self.docs[id]=normalize_string(content)\n",
    "            # normalize content\n",
    "            words = normalize_string(content).split(\" \")\n",
    "            # update the index\n",
    "            for word in words:\n",
    "                self.index[word][id] += 1\n",
    "        new_len =original_len = len(self.docs.keys())\n",
    "        print(f'We have added {new_len-original_len} documents. The engine now has {new_len} documents.')\n",
    "\n",
    "    def load(self,document:str)->None:\n",
    "        '''Load a single document into the search engine. Ideally this should not be used.\n",
    "\n",
    "        Input:\n",
    "            document: str, the new text document to add to the search engine.\n",
    "        '''\n",
    "        new_id = len(self.docs.keys())\n",
    "        self.docs[new_id]=normalize_string(document)\n",
    "        words = normalize_string(document).split(\" \")\n",
    "        for word in words:\n",
    "            self.index[word][new_id]\n",
    "\n",
    "    def num_docs(self)->int:\n",
    "        '''Returns the number of docs\n",
    "\n",
    "        Output:\n",
    "            int: length of docs\n",
    "        '''\n",
    "        return len(self.docs.keys())\n",
    "\n",
    "    def find_ids(self,keyword:string)->dict:\n",
    "        keyword =normalize_string(keyword)\n",
    "        return self.index[keyword]\n",
    "\n",
    "    def bw_idf(self,keyword:str)->float:\n",
    "    # for each term, get the idf\n",
    "        num_docs = self.num_docs()\n",
    "        n_kw = len(self.find_ids(keyword))\n",
    "        return log((num_docs-n_kw+0.5)/(n_kw+0.5)+1)\n",
    "    \n",
    "    def bm25(self, keyword:str)-> dict[str, float]:\n",
    "        result = {}\n",
    "        idf = self.bw_idf(keyword)\n",
    "        avg_ql = sum(len(d) for d in self.docs.values()) / len(self.docs)\n",
    "        for id, freq in self.find_ids(keyword).items():\n",
    "            num = freq * (self.k1+1)\n",
    "            denom = freq+self.k1*(1 - self.b + self.b * len(self.docs[id]) / avg_ql)\n",
    "            result[id]=idf * num /denom\n",
    "        return result\n",
    "    \n",
    "    def bw_search(self,query:str,limit:int=None)->dict[str,float]:\n",
    "        kws = normalize_string(query).split(\" \")\n",
    "        scores ={} # dict[str, float] \n",
    "        for k in kws:\n",
    "            kw_url_score = self.bm25(k)\n",
    "            scores = update_url_scores(scores,kw_url_score)\n",
    "        sort_scores = sorted(scores.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "        if limit is not None:\n",
    "            sort_scores = sort_scores[:limit]\n",
    "        return sort_scores\n",
    "    \n",
    "    def pretty_print(self,ids:list)->list:\n",
    "        '''Prints the quotes instead of a list of ids'''\n",
    "        # get context\n",
    "        output = []\n",
    "        for x in ids:\n",
    "            context = [self.original_docs[x-1],self.original_docs[x],self.original_docs[x+1]]\n",
    "            output.append(context)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 0 documents. The engine now has 144211 documents.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144211"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_engine = search_engine()\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])\n",
    "test_engine.num_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"    (almost smiles, with     irony)   To hate Cardassians.  Well, that    wouldn't be too hard, would it.     We've told him the truth,    Commander.  The truth.  What    Cardassia did to Bajor.  He needed    to know.  I make no apologies for    that...       To us... he isn't even one of...    them... anymore.  He isn't Cardassian,    he's Bajoran.  And we love him as if    he were our own flesh and blood.\",\n",
       "  '   Dabo!  Dabo!  Dabo!',\n",
       "  \"   There's nothing quite so depressing    as a winning streak that won't stop    streaking.\"],\n",
       " ['        Nerys!',\n",
       "  \"        Dabo!        That is dabo, isn't it?\",\n",
       "  \"   I don't see why you insist on    playing this ridiculous game.\"],\n",
       " [\"    (confident of the     house's odds)    I admire your courage...\",\n",
       "  '   Dabo!',\n",
       "  '        Well, what do you know... we have    a winner...'],\n",
       " [\"   The way I see it there are two    possible explanations. Either I'm    more feebleminded than you ever    realized, or you're not as smart    as you think you are.\",\n",
       "  '   Dabo!',\n",
       "  '   Looks like your lucky day.'],\n",
       " ['   If the Dominion comes through the    wormhole, the first battle will be    fought here.  And I intend to be    ready for them.',\n",
       "  '   Dabo!',\n",
       "  \"   You're not leaving?\"],\n",
       " [\"   This isn't funny... we just have    to pick the right one... it's    fifty-fifty... better odds than    you get at the dabo table...\",\n",
       "  '   dabo?',\n",
       "  \"   It's a game... if we get out of    this, I'll teach it to you.        Choose one.\"],\n",
       " [\"   It's really not that interesting.\",\n",
       "  '   Dabo!',\n",
       "  \"   Well, hasn't this been fun! Why    not have a seat, and top off the    evening with a lovely bottle of    springwine?\"],\n",
       " ['   Come on, I know just the thing to    cheer you up.',\n",
       "  '   Dabo!',\n",
       "  \"   She's unbelievable...\"],\n",
       " ['   Do you know the family well?', '   Dabo!', '       Do you?'],\n",
       " ['   Keiko... ', '   Dabo!', \"   I don't want you on this station.\"],\n",
       " ['       ... or a Starfleet Commander who has    one of your relatives in jail.',\n",
       "  '   Dabo!',\n",
       "  \"   Station log.  Stardate xxxxx.x.   The Enterprise has been ordered    to the Lapolis system. They're    scheduled to depart at zero-five    hundred hours after offloading    three runabout class vessels.   Meanwhile, our medical and science    officers are arriving... and I'm    looking forward to a reunion with    a... very old... friend.\"],\n",
       " [\"   Fortune's fates are with you today,    friends... prompt wagers, please...    I'm sorry, Madame, Quark's does not    accept travelers' vouchers... gold    or hard currency, please... final    wagers...\",\n",
       "  '   Dabo!',\n",
       "  \"   What'll you have, Commander?\"],\n",
       " ['   Perfectly.',\n",
       "  '       Dabo!',\n",
       "  '   Computer, analyze test sample thirty-   seven delta.  Detail effects on viral    containment.'],\n",
       " ['   Doctor Surmak Ren.  Former member of    the Higa Metar sect of the Bajoran    underground.  Repatriated to Bajor    upon closing of the Velos Seven    Internment Camp, Stardate 46302.     Current status... unknown.',\n",
       "  '       Dabo!',\n",
       "  '   Having any luck?'],\n",
       " ['   I wish McCoullough were here right    now instead of me.',\n",
       "  '   Dabo!',\n",
       "  '       Aba!  Aba... Aba... Garundi... Dabo...    Garundi... Dabo...'],\n",
       " ['   Just stand there and look like a    doctor.       If you can.',\n",
       "  '   Dabo!!',\n",
       "  \"   We don't have anything like this   on Jupiter Station... or like her.\"],\n",
       " ['   Quark...       Dabo.', '   Dabo!', '   Chief, wait!  Chief...'],\n",
       " [\"   It's a longshot, but if you want to    throw your money away, who am I to    stop you?\",\n",
       "  '   Dabo!',\n",
       "  '       Oh-oh.  Looks like all bets are off.'],\n",
       " ['   Dabo!',\n",
       "  '       Aba!  Aba... Aba... Garundi... Dabo...    Garundi... Dabo...',\n",
       "  \"   No, they couldn't have doubled    again...\"],\n",
       " ['   That sounds like a good idea.', '   Quark...       Dabo.', '   Dabo!']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_results = test_engine.bw_search('dabo',20)\n",
    "# sorted_items = sorted(q_results.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "# sorted_items\n",
    "x= test_engine.pretty_print([x[0] for x in q_results])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "Now that I feel comfortable with the base idea of how I can implement a search engine, I need to fine tune it. \n",
    "\n",
    "1) pre-process text data much better \n",
    "* I should BOW & vectorize the quotes. Then I can also use the other data points (line in episode, speaker, who is spoken to etc). \n",
    "* From the textbook, it seems like BOW outperforms n-grams, but I should also remove stop words & lemmatize them.\n",
    "* This should allow for similarity vector space recommendation models & some other fancy things: e.g. checking if search term is name of character or episode, etc.\n",
    "2) better display \n",
    "* display non-processed text. Get rid of double spaces. Include the speaker, episode, etc. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si649f23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
