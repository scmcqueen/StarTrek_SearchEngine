{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "In this file, we walk through the process of creating a search engine with an inverted index. The class definition was copied & pasted into search_engine.py so that I could import it into other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "import string\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>character</th>\n",
       "      <th>quote</th>\n",
       "      <th>scene</th>\n",
       "      <th>location</th>\n",
       "      <th>view</th>\n",
       "      <th>episode</th>\n",
       "      <th>date</th>\n",
       "      <th>series</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110029</th>\n",
       "      <td>61</td>\n",
       "      <td>DATA</td>\n",
       "      <td>I am reading an ion trail characteristic of a ...</td>\n",
       "      <td>8    INT. BRIDGE (OPTICAL)</td>\n",
       "      <td>BRIDGE</td>\n",
       "      <td>INT.</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>1990-08-20</td>\n",
       "      <td>The Next Generation</td>\n",
       "      <td>180.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86228</th>\n",
       "      <td>260</td>\n",
       "      <td>PICARD</td>\n",
       "      <td>Let us do no such damned thing! What is this n...</td>\n",
       "      <td>91   INT. MAIN BRIDGE</td>\n",
       "      <td>MAIN BRIDGE</td>\n",
       "      <td>INT.</td>\n",
       "      <td>Hide And Q</td>\n",
       "      <td>1987-09-25</td>\n",
       "      <td>The Next Generation</td>\n",
       "      <td>111.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91538</th>\n",
       "      <td>107</td>\n",
       "      <td>JONO</td>\n",
       "      <td>Are you going to return me to my Captain?</td>\n",
       "      <td>14   INT. N.D. LIVING QUARTERS - A LITTLE LATER</td>\n",
       "      <td>N.D. LIVING QUARTER</td>\n",
       "      <td>INT.</td>\n",
       "      <td>Suddenly Human</td>\n",
       "      <td>1990-07-09</td>\n",
       "      <td>The Next Generation</td>\n",
       "      <td>176.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111280</th>\n",
       "      <td>412</td>\n",
       "      <td>RIKER</td>\n",
       "      <td>Take him to a detention cell, Mister Worf. And...</td>\n",
       "      <td>67   INT. SHUTTLEBAY - (OPTICAL)</td>\n",
       "      <td>SHUTTLEBAY -</td>\n",
       "      <td>INT.</td>\n",
       "      <td>A Matter of Time</td>\n",
       "      <td>1991-09-25</td>\n",
       "      <td>The Next Generation</td>\n",
       "      <td>209.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23603</th>\n",
       "      <td>12</td>\n",
       "      <td>BASHIR</td>\n",
       "      <td>Are you saying you agree with General Yiri's d...</td>\n",
       "      <td>5    INT. QUARK'S - SECOND LEVEL</td>\n",
       "      <td>QUARK'</td>\n",
       "      <td>INT.</td>\n",
       "      <td>Profit and Loss</td>\n",
       "      <td>1994-01-13</td>\n",
       "      <td>Deep Space Nine</td>\n",
       "      <td>438.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index character                                              quote  \\\n",
       "110029     61      DATA  I am reading an ion trail characteristic of a ...   \n",
       "86228     260    PICARD  Let us do no such damned thing! What is this n...   \n",
       "91538     107      JONO          Are you going to return me to my Captain?   \n",
       "111280    412     RIKER  Take him to a detention cell, Mister Worf. And...   \n",
       "23603      12    BASHIR  Are you saying you agree with General Yiri's d...   \n",
       "\n",
       "                                                  scene             location  \\\n",
       "110029                       8    INT. BRIDGE (OPTICAL)               BRIDGE   \n",
       "86228                             91   INT. MAIN BRIDGE          MAIN BRIDGE   \n",
       "91538   14   INT. N.D. LIVING QUARTERS - A LITTLE LATER  N.D. LIVING QUARTER   \n",
       "111280                 67   INT. SHUTTLEBAY - (OPTICAL)         SHUTTLEBAY -   \n",
       "23603                  5    INT. QUARK'S - SECOND LEVEL               QUARK'   \n",
       "\n",
       "        view           episode        date               series     file  \n",
       "110029  INT.            Legacy  1990-08-20  The Next Generation  180.txt  \n",
       "86228   INT.        Hide And Q  1987-09-25  The Next Generation  111.txt  \n",
       "91538   INT.    Suddenly Human  1990-07-09  The Next Generation  176.txt  \n",
       "111280  INT.  A Matter of Time  1991-09-25  The Next Generation  209.txt  \n",
       "23603   INT.   Profit and Loss  1994-01-13      Deep Space Nine  438.txt  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by loading in the data\n",
    "complete = pd.read_csv('https://scmcqueen.github.io/StarTrekScriptData/complete_data.csv')\n",
    "# Rename columns\n",
    "complete.columns = ['index', 'character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']\n",
    "# Clean up Character & Quote\n",
    "complete['character'] = complete['character'].apply(lambda text: \" \".join(str(text).split()))\n",
    "complete['quote']=complete['quote'].apply(lambda text: \" \".join(text.split()))\n",
    "# Show sample of data\n",
    "complete.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded in, we may want to define some functions that we will use when creating the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(input_string: str) -> str:\n",
    "    '''This function processes a string by removing punctuation,\n",
    "    making text lowercase, and getting rid of extra spaces\n",
    "\n",
    "    For example:\n",
    "        \"Hello,  HI!!! How are     you?\"\n",
    "    becomes\n",
    "        \"hello hi how are you\"\n",
    "    '''\n",
    "    translation_table = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    string_without_punc = input_string.translate(translation_table)\n",
    "    string_without_double_spaces = ' '.join(string_without_punc.split())\n",
    "    return string_without_double_spaces.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAY WANT TO ALSO LEMMATIZE & DROP STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_url_scores(old: dict[str, float], new: dict[str, float]):\n",
    "    '''This function adds two dictionaries together'''\n",
    "    for url, score in new.items():\n",
    "        if url in old:\n",
    "            old[url] += score\n",
    "        else:\n",
    "            old[url] = score\n",
    "    return old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a Search Engine object with an inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    '''This class creates a search engine object'''\n",
    "    def __init__(self, index:dict[str, dict[str, int]]=None, docs: dict[str, str]=None,\n",
    "        original_docs: dict[str, str]=None,k1:float=1.5,b:float=0.75,\n",
    "        name:str='Default Search Engine',full_data: pd.DataFrame=None):\n",
    "        '''\n",
    "        Instantiate an instance of the search engine class.\n",
    "\n",
    "        Input:\n",
    "            index: dict[str, dict[int,int]], the inverted index\n",
    "            docs: dict[int, str], key is the id of the quote and value is the quote text\n",
    "            original_docs:\n",
    "            k1: float, k1 constant to use for bm25\n",
    "            b: float, b constant to use for bm25\n",
    "            name: string, name used for the search engine instance\n",
    "            full_data:  pd.DataFrame, the original dataset used\n",
    "\n",
    "        Output:\n",
    "            search engine!\n",
    "        '''\n",
    "        # set index\n",
    "        if index is None: self.index = defaultdict(lambda: defaultdict(int))\n",
    "        else: self.index = index\n",
    "        # set docs\n",
    "        if docs is None: self.docs = {}\n",
    "        else: self.docs = docs\n",
    "        # set original docs\n",
    "        if original_docs is None: self.original_docs = {}\n",
    "        else: self.original_docs = original_docs\n",
    "        # set k1\n",
    "        self.k1 = k1\n",
    "        # set b\n",
    "        self.b = b\n",
    "        # set name\n",
    "        self.name = name\n",
    "        # set full_data\n",
    "        self.full_data = full_data\n",
    "\n",
    "    def __str__(self)->str:\n",
    "        '''\n",
    "        Prints a readable name of the search engine\n",
    "\n",
    "        Output:\n",
    "            str: name of the instance\n",
    "        '''\n",
    "        return(self.name)\n",
    "\n",
    "    def bulk_load(self,data:dict,full_data:pd.DataFrame=None)->None:\n",
    "        '''\n",
    "        Bulk loads new documents to the search engine.\n",
    "\n",
    "        Input:\n",
    "            data: dict, the formatted data\n",
    "            full_data: pd.DataFrame, the data with the full info\n",
    "        '''\n",
    "        # get the original size of the docs\n",
    "        original_len = len(self.docs.keys())\n",
    "        # for each index in the data\n",
    "        for ind in data.keys():\n",
    "            content = data[ind] # quote text\n",
    "            # add to original docs\n",
    "            self.original_docs[ind]=content\n",
    "            # normalize content & add to docs\n",
    "            n_content = normalize_string(str(content))\n",
    "            self.docs[ind]=n_content\n",
    "\n",
    "            # now we want to created the inverted index based on words\n",
    "            words = n_content.split(\" \")\n",
    "            for w in words:\n",
    "                self.index[w][ind]+=1 # update count of word per index\n",
    "        # get new length\n",
    "        new_len = len(self.docs.keys())\n",
    "        print(f'We added {new_len-original_len} documents. The engine now has {new_len} documents.')\n",
    "\n",
    "    def individual_load(self, document:str)-> None:\n",
    "        '''\n",
    "        Load a single document into the search engine. Ideally this should not be used.\n",
    "\n",
    "        Input:\n",
    "            document: str, the new text document to add to the search engine.\n",
    "        '''\n",
    "        # assign new id\n",
    "        new_id = len(self.docs.keys())\n",
    "        # add to docs & original docs\n",
    "        self.original_docs[new_id]=document\n",
    "        n_docs = normalize_string(document)\n",
    "        self.docs[new_id]=n_docs\n",
    "        # now we need to update the inverted index\n",
    "        words = n_docs.split(\" \")\n",
    "        for w in words:\n",
    "            self.index[w][new_id]\n",
    "        print(f'Added document \"{document}\" to search engine.')\n",
    "\n",
    "    def num_docs(self)->int:\n",
    "        '''\n",
    "        Returns the number of docs\n",
    "\n",
    "        Output:\n",
    "            int: length of docs\n",
    "        '''\n",
    "        return len(self.docs.keys())\n",
    "\n",
    "    def find_ids(self, keyword:str)->dict:\n",
    "        '''\n",
    "        Find the doc ids that contain a keyword.\n",
    "\n",
    "        Input:\n",
    "            keyword: str, the word to search\n",
    "        Returns:\n",
    "            dict: keys are the indices and the values are\n",
    "                the frequency of the word in the document\n",
    "        '''\n",
    "        key = normalize_string(keyword)\n",
    "        return(self.index[key])\n",
    "\n",
    "    def bw_idf(self,keyword:str)-> float:\n",
    "        '''\n",
    "        Find the inverse document frequency for a term\n",
    "\n",
    "        Input:\n",
    "            keyword: str, word to search\n",
    "\n",
    "        Output:\n",
    "            float: the idf score\n",
    "        '''\n",
    "        num_docs = self.num_docs()\n",
    "        keyword = normalize_string(keyword)\n",
    "        n_kw = len(self.find_ids(keyword))\n",
    "        idf = log((num_docs-n_kw+0.5)/(n_kw+0.5)+1)\n",
    "        return(idf)\n",
    "\n",
    "    def bm25(self,keyword:str)-> dict[str, float]:\n",
    "        '''\n",
    "        Calculate the bm25 score for every document\n",
    "\n",
    "        Input:\n",
    "            keyword: str, word to search\n",
    "\n",
    "        Output:\n",
    "            dict[str, float]: dict of doc ids & the bm25 score\n",
    "        '''\n",
    "        result = {} # instantiate the output\n",
    "        keyword = normalize_string(keyword)\n",
    "        idf = self.bw_idf(keyword) # get the idf score\n",
    "        # get the avg len of a document\n",
    "        avg_ql = sum(len(d) for d in self.docs.values()) / len(self.docs)\n",
    "        # calculate the bw score for each\n",
    "        for id, freq in self.find_ids(keyword).items(): # for doc id & word freq\n",
    "            numerator = freq*(self.k1+1)\n",
    "            denominator = freq+self.k1*(1 - self.b + self.b * len(self.docs[id]) / avg_ql)\n",
    "            result[id]=idf*numerator / denominator\n",
    "        # return dict with the ids & scores\n",
    "        return result\n",
    "\n",
    "    def bw_search(self,query:str,limit:int=None,context:bool=False)->dict[str,float]:\n",
    "        '''\n",
    "        Completes the bm25 search of the documents using the query and returns\n",
    "\n",
    "        Input:\n",
    "            query: str, the query to search through the documents\n",
    "            limit: int, limits the number of documents\n",
    "            context: bool, if true return also the bm-scores of the lines before & after the selected lines.\n",
    "                There must exist a limit for this to be true.\n",
    "\n",
    "        Output:\n",
    "            dict[str,float]: the index and the bm25 score\n",
    "        '''\n",
    "        # split the query & normalize it\n",
    "        kws = normalize_string(query).split(\" \")\n",
    "        scores = {} # initialize output\n",
    "        for k in kws:\n",
    "            kw_score = self.bm25(k) # get the scores for this word\n",
    "            scores = update_url_scores(scores,kw_score) # add the dict values together\n",
    "        # sort the scores by the bm25 score\n",
    "        sorted_scores = sorted(scores.items(), key=lambda kv: (kv[1], kv[0]),reverse=True)\n",
    "        output = sorted_scores.copy()\n",
    "        # limit the score output\n",
    "        if limit is not None:\n",
    "            output = sorted_scores[:limit]\n",
    "            # check if we need to get context\n",
    "            if context:\n",
    "                # get index, score, score of line before, score of line after\n",
    "                output = [[x[0],x[1], scores[x[0]-1] if x[0]-1 in scores.keys() else 0, scores[x[0]+1] if x[0]+1 in scores.keys() else 0 ] for x in output]\n",
    "\n",
    "        return(output)\n",
    "\n",
    "    def pretty_print(self, index:int)->str:\n",
    "        '''\n",
    "        Prints the speaker, line, and context for a specific query.\n",
    "\n",
    "        Input:\n",
    "            index: int, the index in the data full data frame.\n",
    "\n",
    "        Output:\n",
    "            string: a well formatted string\n",
    "        '''\n",
    "        # maybe could do this more efficiently\n",
    "        q = self.full_data.iloc[index]['quote'] # get quote\n",
    "        char = self.full_data.iloc[index]['character'] # get character (& make lowercase)\n",
    "        ep = self.full_data.iloc[index]['episode'] # get episode\n",
    "        series = self.full_data.iloc[index]['series'] # get series\n",
    "        date = self.full_data.iloc[index]['date'] # get date\n",
    "        # previous values\n",
    "        p_q = self.full_data.iloc[index-1]['quote'] # get previous quote\n",
    "        p_char = self.full_data.iloc[index-1]['character'] # get previous character (& make lowercase)\n",
    "        # next values\n",
    "        n_q = self.full_data.iloc[index+1]['quote'] # get next quote\n",
    "        n_char = self.full_data.iloc[index+1]['character'] # get next character (& make lowercase)\n",
    "\n",
    "        output = f'{p_char}: {p_q} \\n {char}: {q} \\n {n_char}: {n_q} \\n \\n \"{ep}\", {series}, {date}'\n",
    "        return(output)\n",
    "    \n",
    "    def old_pretty_print(self,ids:list)->list:\n",
    "        '''Prints the quotes instead of a list of ids'''\n",
    "        # get context\n",
    "        output = []\n",
    "        for x in ids:\n",
    "            context = [self.full_data['character'].iloc[x-1]+': '+self.original_docs[x-1],\n",
    "                       self.full_data['character'].iloc[x]+': '+self.original_docs[x],\n",
    "                       self.full_data['character'].iloc[x+1]+': '+self.original_docs[x+1]]\n",
    "            output.append(context)\n",
    "        return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We added 144211 documents. The engine now has 144211 documents.\n"
     ]
    }
   ],
   "source": [
    "# create instance of search engine\n",
    "bm25_engine = search_engine(name='BM25 Engine',full_data=complete)\n",
    "# load data in bulk\n",
    "bm25_engine.bulk_load(complete[['quote']].to_dict()['quote'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I have a search engine! Let's do a test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                  56\n",
       "character                           ZOLAN\n",
       "quote                   Dabo! Dabo! Dabo!\n",
       "scene        19   INT. QUARK'S - CLOSE ON\n",
       "location                           QUARK'\n",
       "view                                 INT.\n",
       "episode                       Cardassians\n",
       "date                           1993-08-16\n",
       "series                    Deep Space Nine\n",
       "file                              425.txt\n",
       "Name: 38743, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete.iloc[38743]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38743, 14.950076796302916, 0, 0],\n",
       " [12663, 12.64571859691301, 0, 0],\n",
       " [61458, 12.50535557934936, 0, 0],\n",
       " [61353, 12.50535557934936, 0, 0],\n",
       " [58731, 12.50535557934936, 0, 0],\n",
       " [53295, 12.50535557934936, 5.201571163523684, 0],\n",
       " [46327, 12.50535557934936, 0, 0],\n",
       " [46320, 12.50535557934936, 0, 0],\n",
       " [38752, 12.50535557934936, 0, 0],\n",
       " [33055, 12.50535557934936, 0, 0],\n",
       " [32506, 12.50535557934936, 0, 0],\n",
       " [32500, 12.50535557934936, 0, 0],\n",
       " [25198, 12.50535557934936, 0, 0],\n",
       " [25187, 12.50535557934936, 0, 0],\n",
       " [23268, 12.50535557934936, 0, 11.785538827271429],\n",
       " [17130, 12.50535557934936, 0, 0],\n",
       " [11519, 12.50535557934936, 11.59258591664298, 0],\n",
       " [1980, 12.50535557934936, 0, 0],\n",
       " [23269, 11.785538827271429, 12.50535557934936, 0],\n",
       " [11518, 11.59258591664298, 0, 12.50535557934936]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_results = bm25_engine.bw_search('dabo',20,context=True)\n",
    "q_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bm25</th>\n",
       "      <th>prev_bm25</th>\n",
       "      <th>next_bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38743</td>\n",
       "      <td>14.950077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12663</td>\n",
       "      <td>12.645719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61458</td>\n",
       "      <td>12.505356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61353</td>\n",
       "      <td>12.505356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58731</td>\n",
       "      <td>12.505356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       bm25  prev_bm25  next_bm25\n",
       "0  38743  14.950077        0.0        0.0\n",
       "1  12663  12.645719        0.0        0.0\n",
       "2  61458  12.505356        0.0        0.0\n",
       "3  61353  12.505356        0.0        0.0\n",
       "4  58731  12.505356        0.0        0.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(q_results)\n",
    "results_df.columns = ['index','bm25','prev_bm25','next_bm25']\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROKA: (almost smiles, with irony) To hate Cardassians. Well, that wouldn't be too hard, would it. We've told him the truth, Commander. The truth. What Cardassia did to Bajor. He needed to know. I make no apologies for that... To us... he isn't even one of... them... anymore. He isn't Cardassian, he's Bajoran. And we love him as if he were our own flesh and blood. \n",
      " ZOLAN: Dabo! Dabo! Dabo! \n",
      " QUARK: There's nothing quite so depressing as a winning streak that won't stop streaking. \n",
      " \n",
      " \"Cardassians\", Deep Space Nine, 1993-08-16\n",
      "\n",
      "\n",
      "GHEMOR: Nerys! \n",
      " WEYOUN: Dabo! That is dabo, isn't it? \n",
      " DUKAT: I don't see why you insist on playing this ridiculous game. \n",
      " \n",
      " \"Ties of Blood and Water\", Deep Space Nine, 1997-01-24\n",
      "\n",
      "\n",
      "QUARK: (confident of the house's odds) I admire your courage... \n",
      " S: Dabo! \n",
      " QUARK: Well, what do you know... we have a winner... \n",
      " \n",
      " \"Statistical Probabilities\", Deep Space Nine, 1997-09-26\n",
      "\n",
      "\n",
      "O'BRIEN: The way I see it there are two possible explanations. Either I'm more feebleminded than you ever realized, or you're not as smart as you think you are. \n",
      " S: Dabo! \n",
      " QUARK: Looks like your lucky day. \n",
      " \n",
      " \"Statistical Probabilities\", Deep Space Nine, 1997-09-26\n",
      "\n",
      "\n",
      "SISKO: If the Dominion comes through the wormhole, the first battle will be fought here. And I intend to be ready for them. \n",
      " MARDAH: Dabo! \n",
      " MARDAH: You're not leaving? \n",
      " \n",
      " \"The Abandoned\", Deep Space Nine, 1994-08-30\n",
      "\n",
      "\n",
      "QUARK: This isn't funny... we just have to pick the right one... it's fifty-fifty... better odds than you get at the dabo table... \n",
      " HANOK: dabo? \n",
      " QUARK: It's a game... if we get out of this, I'll teach it to you. Choose one. \n",
      " \n",
      " \"Starship Down\", Deep Space Nine, 1995-09-11\n",
      "\n",
      "\n",
      "SARINA: It's really not that interesting. \n",
      " S: Dabo! \n",
      " QUARK: Well, hasn't this been fun! Why not have a seat, and top off the evening with a lovely bottle of springwine? \n",
      " \n",
      " \"Chrysalis\", Deep Space Nine, 1998-08-14\n",
      "\n",
      "\n",
      "BASHIR: Come on, I know just the thing to cheer you up. \n",
      " S: Dabo! \n",
      " O'BRIEN: She's unbelievable... \n",
      " \n",
      " \"Chrysalis\", Deep Space Nine, 1998-08-14\n",
      "\n",
      "\n",
      "BASHIR: Do you know the family well? \n",
      " ZOLAN: Dabo! \n",
      " BASHIR: Do you? \n",
      " \n",
      " \"Cardassians\", Deep Space Nine, 1993-08-16\n",
      "\n",
      "\n",
      "O'BRIEN: Keiko... \n",
      " DABO GIRL: Dabo! \n",
      " ODO: I don't want you on this station. \n",
      " \n",
      " \"CAST\", Deep Space Nine, 1992-09-18\n",
      "\n",
      "\n",
      "QUARK: ... or a Starfleet Commander who has one of your relatives in jail. \n",
      " PIT BOSS: Dabo! \n",
      " SISKO: Station log. Stardate xxxxx.x. The Enterprise has been ordered to the Lapolis system. They're scheduled to depart at zero-five hundred hours after offloading three runabout class vessels. Meanwhile, our medical and science officers are arriving... and I'm looking forward to a reunion with a... very old... friend. \n",
      " \n",
      " \"#40511-721\", Deep Space Nine, 1992-08-10\n",
      "\n",
      "\n",
      "PIT BOSS: Fortune's fates are with you today, friends... prompt wagers, please... I'm sorry, Madame, Quark's does not accept travelers' vouchers... gold or hard currency, please... final wagers... \n",
      " FEMALE: Dabo! \n",
      " QUARK: What'll you have, Commander? \n",
      " \n",
      " \"#40511-721\", Deep Space Nine, 1992-08-10\n",
      "\n",
      "\n",
      "QUARK: Perfectly. \n",
      " QUARK: Dabo! \n",
      " BASHIR: Computer, analyze test sample thirty- seven delta. Detail effects on viral containment. \n",
      " \n",
      " \"Babel\", Deep Space Nine, 1992-10-07\n",
      "\n",
      "\n",
      "COMPUTER: Doctor Surmak Ren. Former member of the Higa Metar sect of the Bajoran underground. Repatriated to Bajor upon closing of the Velos Seven Internment Camp, Stardate 46302. Current status... unknown. \n",
      " QUARK: Dabo! \n",
      " ODO: Having any luck? \n",
      " \n",
      " \"Babel\", Deep Space Nine, 1992-10-07\n",
      "\n",
      "\n",
      "SISKO: I wish McCoullough were here right now instead of me. \n",
      " FEMALE: Dabo! \n",
      " WADI CROWD: Aba! Aba... Aba... Garundi... Dabo... Garundi... Dabo... \n",
      " \n",
      " \"Move Along Home\", Deep Space Nine, 1992-12-07\n",
      "\n",
      "\n",
      "ZIMMERMAN: Just stand there and look like a doctor. If you can. \n",
      " LEETA: Dabo!! \n",
      " ZIMMERMAN: We don't have anything like this on Jupiter Station... or like her. \n",
      " \n",
      " \"Doctor Bashir, I Presume?\", Deep Space Nine, 1996-12-13\n",
      "\n",
      "\n",
      "O'BRIEN: Quark... Dabo. \n",
      " WOMAN: Dabo! \n",
      " QUARK: Chief, wait! Chief... \n",
      " \n",
      " \"Visionary\", Deep Space Nine, 1995-01-03\n",
      "\n",
      "\n",
      "QUARK: It's a longshot, but if you want to throw your money away, who am I to stop you? \n",
      " CROWD: Dabo! \n",
      " QUARK: Oh-oh. Looks like all bets are off. \n",
      " \n",
      " \"Distant Voices\", Deep Space Nine, 1995-01-11\n",
      "\n",
      "\n",
      "FEMALE: Dabo! \n",
      " WADI CROWD: Aba! Aba... Aba... Garundi... Dabo... Garundi... Dabo... \n",
      " QUARK: No, they couldn't have doubled again... \n",
      " \n",
      " \"Move Along Home\", Deep Space Nine, 1992-12-07\n",
      "\n",
      "\n",
      "BASHIR: That sounds like a good idea. \n",
      " O'BRIEN: Quark... Dabo. \n",
      " WOMAN: Dabo! \n",
      " \n",
      " \"Visionary\", Deep Space Nine, 1995-01-03\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in q_results:\n",
    "    print(bm25_engine.pretty_print(x[0]))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
