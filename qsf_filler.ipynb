{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Write Qualtrics Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import search_engine as ss #simple_search_func as ss\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the qsf!\n",
    "# with open('Query_Template.qsf', 'r') as file:\n",
    "with open('Query_Template.qsf', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_dict = {\n",
    "    'love': ['hello', 'hi', 'are you', 'darling', 'sweetheart', 'honey', 'romance', 'affection', 'passion', 'devotion', \n",
    "             'adore', 'cherish', 'fondness', 'embrace', 'beloved', 'cuddle', 'valentine', 'kiss', 'heart', 'soulmate'],\n",
    "    'sadness': ['meow', 'meow meow', 'meowwww', 'tears', 'gloom', 'despair', 'melancholy', 'sorrow', 'blue', 'grief', \n",
    "                'heartache', 'mourn', 'loneliness', 'misery', 'pain', 'regret', 'weep', 'hurt', 'lost', 'downcast'],\n",
    "    'kiss': ['smoocher', 'kombucher', 'peck', 'smooch', 'liplock', 'mwah', 'pucker', 'osculation', 'romantic', 'passionate',\n",
    "             'sweet', 'gentle', 'soft', 'warm', 'butterfly', 'cheek', 'forehead', 'eskimo', 'lovebite', 'chaste'],\n",
    "    'happiness': ['joy', 'smile', 'laughter', 'cheer', 'delight', 'bliss', 'glee', 'ecstatic', 'merry', 'euphoria', \n",
    "                  'sunny', 'content', 'radiant', 'jubilant', 'bubbly', 'grateful', 'optimistic', 'carefree', 'vivacious', 'buoyant'],\n",
    "    'anger': ['rage', 'fury', 'wrath', 'outrage', 'resentment', 'bitterness', 'spite', 'grudge', 'irritation', 'annoyance',\n",
    "              'exasperation', 'hostility', 'hatred', 'indignation', 'fuming', 'seething', 'mad', 'infuriated', 'irate', 'tempest'],\n",
    "    'fear': ['terror', 'panic', 'dread', 'fright', 'horror', 'alarm', 'anxiety', 'nervous', 'uneasy', 'apprehension',\n",
    "             'timid', 'startle', 'tremble', 'phobia', 'shiver', 'quiver', 'spooked', 'petrified', 'chill', 'paranoia'],\n",
    "    'surprise': ['shock', 'amazement', 'astonishment', 'wonder', 'startled', 'stunned', 'flabbergasted', 'aghast', 'dumbfounded', 'jolted',\n",
    "                 'marvel', 'unexpected', 'perplexed', 'bewildered', 'gobsmacked', 'astounded', 'overwhelmed', 'speechless', 'baffled', 'staggered'],\n",
    "    'friendship': ['bond', 'companion', 'ally', 'trust', 'loyal', 'camaraderie', 'mate', 'bro', 'sisterhood', 'brotherhood',\n",
    "                   'affection', 'partnership', 'support', 'understanding', 'team', 'respect', 'connect', 'harmony', 'together', 'kindred'],\n",
    "    'jealousy': ['envy', 'resent', 'covet', 'green-eyed', 'possessive', 'suspicion', 'mistrust', 'distrust', 'bitterness', 'spite',\n",
    "                 'comparison', 'insecurity', 'longing', 'competitiveness', 'inferiority', 'grudge', 'fuming', 'anger', 'watchful', 'wary'],\n",
    "    'nostalgia': ['memories', 'past', 'bittersweet', 'longing', 'reminisce', 'yearning', 'flashback', 'old days', 'sentimental', 'melancholy',\n",
    "                  'childhood', 'throwback', 'wistful', 'retro', 'antique', 'classic', 'golden days', 'vintage', 'heartwarming', 'timeless'],\n",
    "    'fear2': ['terror', 'panic', 'dread', 'fright', 'horror', 'alarm', 'anxiety', 'nervous', 'uneasy', 'apprehension',\n",
    "             'timid', 'startle', 'tremble', 'phobia', 'shiver', 'quiver', 'spooked', 'petrified', 'chill', 'paranoia'],\n",
    "    'surprise2': ['shock', 'amazement', 'astonishment', 'wonder', 'startled', 'stunned', 'flabbergasted', 'aghast', 'dumbfounded', 'jolted',\n",
    "                 'marvel', 'unexpected', 'perplexed', 'bewildered', 'gobsmacked', 'astounded', 'overwhelmed', 'speechless', 'baffled', 'staggered'],\n",
    "    'friendship2': ['bond', 'companion', 'ally', 'trust', 'loyal', 'camaraderie', 'mate', 'bro', 'sisterhood', 'brotherhood',\n",
    "                   'affection', 'partnership', 'support', 'understanding', 'team', 'respect', 'connect', 'harmony', 'together', 'kindred'],\n",
    "    'jealousy2': ['envy', 'resent', 'covet', 'green-eyed', 'possessive', 'suspicion', 'mistrust', 'distrust', 'bitterness', 'spite',\n",
    "                 'comparison', 'insecurity', 'longing', 'competitiveness', 'inferiority', 'grudge', 'fuming', 'anger', 'watchful', 'wary'],\n",
    "    'nostalgia2': ['memories', 'past', 'bittersweet', 'longing', 'reminisce', 'yearning', 'flashback', 'old days', 'sentimental', 'melancholy',\n",
    "                  'childhood', 'throwback', 'wistful', 'retro', 'antique', 'classic', 'golden days', 'vintage', 'heartwarming', 'timeless']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(choices_dict.keys())# will be dict keys\n",
    "counter = 0\n",
    "next_topic=None\n",
    "\n",
    "\n",
    "# iterate\n",
    "for x in data['SurveyElements']:\n",
    "    if type(x['Payload']) != dict:\n",
    "        continue\n",
    "    if 'QuestionType' not in x['Payload'].keys():\n",
    "        continue\n",
    "    if x['Payload']['QuestionType']=='MC': # group rank, influences others\n",
    "        text = topics[counter]\n",
    "        old_text = x['SecondaryAttribute']\n",
    "        new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "        x['Payload']['QuestionDescription']= new_q\n",
    "        x['SecondaryAttribute'] = new_q\n",
    "        x['Payload']['QuestionText']= new_q\n",
    "        choices = choices_dict[text]\n",
    "        new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "        x['Payload']['Choices']=new_choices\n",
    "        x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        counter +=1\n",
    "counter = 0\n",
    "for x in data['SurveyElements']:\n",
    "    if type(x['Payload']) != dict:\n",
    "        continue\n",
    "    if 'QuestionType' not in x['Payload'].keys():\n",
    "        continue\n",
    "    if x['Payload']['QuestionType']=='RO': # rank only, depends on other\n",
    "        # THIS COMES FIRST\n",
    "        # update Secondary Attribute: replace whatever is in \"\"\n",
    "        text = topics[counter]\n",
    "        next_topic = text\n",
    "        old_text = x['SecondaryAttribute']\n",
    "        new_q = f'Rank these quotes on how funny they are!'\n",
    "        x['SecondaryAttribute'] = new_q\n",
    "        # update ['Payload']['QuestionText'] replace whatever is in \"\"\n",
    "        x['Payload']['QuestionText']= new_q\n",
    "        x['Payload']['QuestionDescription']= new_q\n",
    "        counter+=1\n",
    "        #counter +=1\n",
    "\n",
    "# save\n",
    "with open('test.qsf', 'w') as json_file:\n",
    "    json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a function\n",
    "\n",
    "def new_survey_file(choices_dict:dict,file_name:str,template_name:str='Query_Template.qsf'):\n",
    "    with open(template_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    topics = list(choices_dict.keys())# will be dict keys\n",
    "    c_topics = topics.copy()\n",
    "    # surveyid = 'newstring'\n",
    "\n",
    "    # iterate\n",
    "    for x in data['SurveyElements']:\n",
    "        if type(x['Payload']) != dict:\n",
    "            continue\n",
    "        if 'QuestionType' not in x['Payload'].keys():\n",
    "            continue\n",
    "        # x['SurveyID']= surveyid\n",
    "        if x['Payload']['QuestionType']=='MC': # group rank, influences others\n",
    "            text = topics.pop()\n",
    "            new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            choices = choices_dict[text]\n",
    "            new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "            x['Payload']['Choices']=new_choices\n",
    "            x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        if x['Payload']['QuestionType']=='RO': # rank only, depends on other\n",
    "            # update Secondary Attribute: replace whatever is in \"\"\n",
    "            text = c_topics.pop()\n",
    "            new_q = f'Rank these quotes on how funny they are!'\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            # update ['Payload']['QuestionText'] replace whatever is in \"\"\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "\n",
    "    # save\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up examples\n",
    "\n",
    "Now that I have the function written, I need to load up the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We added 144211 documents. The engine now has 144211 documents.\n"
     ]
    }
   ],
   "source": [
    "# load up that search\n",
    "complete = pd.read_csv('https://scmcqueen.github.io/StarTrekScriptData/complete_data.csv')\n",
    "complete.columns = ['index','character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']\n",
    "complete['quote']=complete['quote'].apply(lambda text: \" \".join(text.split()))\n",
    "complete['character']=complete['character'].fillna('NA')\n",
    "# test_engine = ss.search_engine()\n",
    "# test_engine.bulk_load(complete[['quote']].to_dict()['quote'])\n",
    "# create instance of search engine\n",
    "test_engine = ss.search_engine(name='BM25 Engine',full_data=complete)\n",
    "# load data in bulk\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=test_engine.bw_search('candle',20,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "choices = []\n",
    "search_term = []\n",
    "bm25 = [] # new\n",
    "bm25_prev = []\n",
    "bm25_next = []\n",
    "file_input = {}\n",
    "\n",
    "for term in keywords_1:\n",
    "    # do the search\n",
    "    results=test_engine.bw_search(term,20,True)\n",
    "    search_results = test_engine.old_pretty_print([x[0] for x in results])\n",
    "    # update values\n",
    "    t_ind = [x[0] for x in results]\n",
    "    t_choices = [' '.join(x) for x in search_results]\n",
    "    #t_choices = [test_engine.pretty_print(x[0]) for x in results]\n",
    "    t_search = [term]*len(t_ind)\n",
    "    # update big list\n",
    "    indices+=t_ind\n",
    "    choices+=t_choices\n",
    "    search_term+=t_search\n",
    "    bm25 +=[x[1] for x in results]\n",
    "    bm25_prev +=[x[2] for x in results]\n",
    "    bm25_next +=[x[3] for x in results]\n",
    "    # update the dict\n",
    "    file_input[term] = t_choices  \n",
    "\n",
    "#new_survey_file(choices_dict=file_input,file_name='Evaluation/day_1.qsf',template_name='Query_Template.qsf')\n",
    "pd.DataFrame({'indices':indices,'choices':choices,'search':search_term,'bm25':bm25,'prev_bm25':bm25_prev,'next_bm25':bm25_next}).to_csv('Evaluation/day_1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>choices</th>\n",
       "      <th>search</th>\n",
       "      <th>bm25</th>\n",
       "      <th>prev_bm25</th>\n",
       "      <th>next_bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44542</td>\n",
       "      <td>JOSEPH: He stole a candle. O'BRIEN: One candle...</td>\n",
       "      <td>candle</td>\n",
       "      <td>14.147200</td>\n",
       "      <td>13.037027</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44541</td>\n",
       "      <td>O'BRIEN: What did he do to deserve this? JOSEP...</td>\n",
       "      <td>candle</td>\n",
       "      <td>13.037027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112905</td>\n",
       "      <td>TROI: Many things improve with age... maybe yo...</td>\n",
       "      <td>candle</td>\n",
       "      <td>11.491176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88378</td>\n",
       "      <td>BEVERLY: Computer, secure door. BEVERLY: I lit...</td>\n",
       "      <td>candle</td>\n",
       "      <td>11.378741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88194</td>\n",
       "      <td>QUINT: There's a lot of things she didn't tell...</td>\n",
       "      <td>candle</td>\n",
       "      <td>11.054260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>108760</td>\n",
       "      <td>Q: After our last encounter, I was asked to le...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>6.681643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>79522</td>\n",
       "      <td>\"Q\" : You show promise, my good fellow. PICARD...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>6.638868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>119412</td>\n",
       "      <td>GEORDI: I'll be honest with you. We don't know...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>6.354117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>140566</td>\n",
       "      <td>TROI: Feelings aren't positive or negative Dat...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>5.952888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>96655</td>\n",
       "      <td>DATA: The moon's altitude is fifty-five thousa...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>5.952888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indices                                            choices    search  \\\n",
       "0      44542  JOSEPH: He stole a candle. O'BRIEN: One candle...    candle   \n",
       "1      44541  O'BRIEN: What did he do to deserve this? JOSEP...    candle   \n",
       "2     112905  TROI: Many things improve with age... maybe yo...    candle   \n",
       "3      88378  BEVERLY: Computer, secure door. BEVERLY: I lit...    candle   \n",
       "4      88194  QUINT: There's a lot of things she didn't tell...    candle   \n",
       "..       ...                                                ...       ...   \n",
       "172   108760  Q: After our last encounter, I was asked to le...  humanity   \n",
       "173    79522  \"Q\" : You show promise, my good fellow. PICARD...  humanity   \n",
       "174   119412  GEORDI: I'll be honest with you. We don't know...  humanity   \n",
       "175   140566  TROI: Feelings aren't positive or negative Dat...  humanity   \n",
       "176    96655  DATA: The moon's altitude is fifty-five thousa...  humanity   \n",
       "\n",
       "          bm25  prev_bm25  next_bm25  \n",
       "0    14.147200  13.037027     0.0000  \n",
       "1    13.037027   0.000000    14.1472  \n",
       "2    11.491176   0.000000     0.0000  \n",
       "3    11.378741   0.000000     0.0000  \n",
       "4    11.054260   0.000000     0.0000  \n",
       "..         ...        ...        ...  \n",
       "172   6.681643   0.000000     0.0000  \n",
       "173   6.638868   0.000000     0.0000  \n",
       "174   6.354117   0.000000     0.0000  \n",
       "175   5.952888   0.000000     0.0000  \n",
       "176   5.952888   0.000000     0.0000  \n",
       "\n",
       "[177 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'indices':indices,'choices':choices,'search':search_term,'bm25':bm25,'prev_bm25':bm25_prev,'next_bm25':bm25_next})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity',\n",
    "               'story', 'religion', 'child', 'molly','counselor']\n",
    "keywords_2 =  ['archaeology','chateau','trial','fiction','romance','wedding','father','kahless','chocolate','future',\n",
    "               'bridge','saucer','coffee','romulans','colony']\n",
    "keywords_3 =  ['raktajino','commit no errors','tanagra','borg','cardassia','poetry','spot','assimilate','unusual','barclay',\n",
    "               'acquisition','rules','vedek','warp crystal',\"bat'leth\"]\n",
    "keywords_4 =  ['blood wine','gagh','cook','celebrate','impossible','earl grey','jake','geordi','riker','poker',\n",
    "               'phaser','occupation','conscious minds','tailor','neutral zone']\n",
    "keywords_5 =  ['men','women','miles','worf','bashir','commander','captain','kira','troi','guinan',\n",
    "               'shields','unification','mister spock','tribble','android']\n",
    "keywords_6 =  ['unraveled','friendship','hailing frequencies','universe','traveler','wesley','good tea','good book','make it so','flute',\n",
    "               'neutrino levels','noonian soong','breen','evidence','vacation']\n",
    "keywords_7 =  ['memory','merry man','obedient','honor','san francisco','new orleans','liberation','imagination','maquis','tribunal',\n",
    "               'trill','lore','risa','detective','ezri']\n",
    "keywords_8 =  ['not picard','ice cream','morn','weyoun','dukat','civilization','replicators','truth','lunch','past',\n",
    "               'empath','betray','warp bubble','jadzia','pregnant']\n",
    "keywords_9 =  ['vineyard','lwaxana','bucket','justice is justice','espionage','same lie','mother','klingon','baseball','moriarty',\n",
    "               'vulcan','moon','lower decks','the academy','full impulse']\n",
    "keywords_10 =  ['enterprise','ferengi','nagus','death','root beer','alpha quadrant','wormhole','tasha','holosuite','holmes',\n",
    "                'the defiant','ensign ro','dabo girl','secret agent','oo-mox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {1:keywords_1,\n",
    "            2:keywords_2,\n",
    "            3:keywords_3,\n",
    "            4:keywords_4,\n",
    "            5:keywords_5,\n",
    "            6:keywords_6,\n",
    "            7:keywords_7,\n",
    "            8:keywords_8,\n",
    "            9:keywords_9,\n",
    "            10:keywords_10\n",
    "            }\n",
    "\n",
    "for x in keywords.keys():\n",
    "    counter = str(x)\n",
    "    t_keys = keywords[x]\n",
    "\n",
    "    indices = []\n",
    "    choices = []\n",
    "    search_term = []\n",
    "    bm25 = [] # new\n",
    "    bm25_prev = []\n",
    "    bm25_next = []\n",
    "    file_input = {}\n",
    "\n",
    "    for term in t_keys:\n",
    "        # do the search\n",
    "        results=test_engine.bw_search(term,20,True)\n",
    "        #search_results = test_engine.pretty_print([x[0] for x in results])\n",
    "        # update values\n",
    "        t_ind = [x[0] for x in results]\n",
    "        #t_choices = [' '.join(x) for x in search_results]\n",
    "        t_choices = [test_engine.pretty_print(x[0]) for x in results]\n",
    "        t_search = [term]*len(t_ind)\n",
    "        # update big list\n",
    "        indices+=t_ind\n",
    "        choices+=t_choices\n",
    "        search_term+=t_search\n",
    "        bm25 +=[x[1] for x in results]\n",
    "        bm25_prev +=[x[2] for x in results]\n",
    "        bm25_next +=[x[3] for x in results]\n",
    "        # update the dict\n",
    "        file_input[term] = t_choices\n",
    "\n",
    "    #new_survey_file(choices_dict=file_input,file_name=f'Evaluation/day_{counter}.qsf',template_name='Query_Template.qsf')\n",
    "    pd.DataFrame({'indices':indices,'choices':choices,'search':search_term,'bm25':bm25,'prev_bm25':bm25_prev,'next_bm25':bm25_next}).to_csv(f'Evaluation/day_{counter}_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(results_path:str='Evaluation/Results/day2_skyeler_only.tsv',questions_path:str='Evaluation/day_2_data.csv'):\n",
    "    # start by reading a file\n",
    "\n",
    "    results = pd.read_csv(results_path)\n",
    "    questions_ids = pd.read_csv(questions_path,index_col=0)\n",
    "    questions_ids.columns = ['indices', 'quote', 'query','bm25','prevbm25','nextbm25']\n",
    "    results =results.drop(columns=['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage'])\n",
    "    cols = results.columns\n",
    "\n",
    "    ranking_cols = [x for x in list(cols) if '_' in x]\n",
    "    q_col = [x for x in list(cols) if 'Q' in x and '_' not in x and 'Q1'!=x]\n",
    "    questions = results[ranking_cols].T\n",
    "\n",
    "    # # query+map should be diff\n",
    "    questions = questions.reset_index()\n",
    "    questions['query']=questions[0].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "    questions['index']=questions['index'].apply(lambda x: x[:x.index('_')])\n",
    "    query_map = questions[['index','query']]\n",
    "\n",
    "    col_results = results[ranking_cols].T\n",
    "\n",
    "    col_results.columns = ['question','id','ranking']\n",
    "    col_results = col_results.reset_index()\n",
    "    col_results['quote']=col_results['question'].apply(lambda x: x[x.index('-')+2:])\n",
    "    col_results['index'] = col_results['index'].apply(lambda x: x[:x.index('_')])\n",
    "    col_results['query']=col_results['question'].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "    result = questions_ids.merge(col_results[['query','quote','ranking']],on=['query','quote'],how='left')\n",
    "    result['ranking']=result['ranking'].fillna(-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3_1</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID4_1\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3_2</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID4_2\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3_3</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID4_3\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q3_4</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID4_4\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3_5</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID4_5\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Q31_26</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID32_26\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bajor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Q31_27</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID32_27\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bajor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Q31_28</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID32_28\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bajor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Q31_29</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID32_29\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bajor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Q31_30</td>\n",
       "      <td>Rank these quotes on how funny they are for th...</td>\n",
       "      <td>{\"ImportId\":\"QID32_30\"}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bajor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                                  0  \\\n",
       "0      Q3_1  Rank these quotes on how funny they are for th...   \n",
       "1      Q3_2  Rank these quotes on how funny they are for th...   \n",
       "2      Q3_3  Rank these quotes on how funny they are for th...   \n",
       "3      Q3_4  Rank these quotes on how funny they are for th...   \n",
       "4      Q3_5  Rank these quotes on how funny they are for th...   \n",
       "..      ...                                                ...   \n",
       "367  Q31_26  Rank these quotes on how funny they are for th...   \n",
       "368  Q31_27  Rank these quotes on how funny they are for th...   \n",
       "369  Q31_28  Rank these quotes on how funny they are for th...   \n",
       "370  Q31_29  Rank these quotes on how funny they are for th...   \n",
       "371  Q31_30  Rank these quotes on how funny they are for th...   \n",
       "\n",
       "                           1    2   query  \n",
       "0      {\"ImportId\":\"QID4_1\"}  NaN  doctor  \n",
       "1      {\"ImportId\":\"QID4_2\"}  NaN  doctor  \n",
       "2      {\"ImportId\":\"QID4_3\"}  NaN  doctor  \n",
       "3      {\"ImportId\":\"QID4_4\"}  NaN  doctor  \n",
       "4      {\"ImportId\":\"QID4_5\"}  NaN  doctor  \n",
       "..                       ...  ...     ...  \n",
       "367  {\"ImportId\":\"QID32_26\"}  NaN   bajor  \n",
       "368  {\"ImportId\":\"QID32_27\"}  NaN   bajor  \n",
       "369  {\"ImportId\":\"QID32_28\"}  NaN   bajor  \n",
       "370  {\"ImportId\":\"QID32_29\"}  NaN   bajor  \n",
       "371  {\"ImportId\":\"QID32_30\"}  NaN   bajor  \n",
       "\n",
       "[372 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_path = 'Evaluation/Results/day1_skyeler_only.csv'\n",
    "questions_path='Evaluation/day_1_data.csv'\n",
    "\n",
    "results = pd.read_csv(results_path)\n",
    "questions_ids = pd.read_csv(questions_path,index_col=0)\n",
    "questions_ids.columns = ['indices', 'quote', 'query','bm25','prevbm25','nextbm25']\n",
    "results =results.drop(columns=['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage'])\n",
    "cols = results.columns\n",
    "\n",
    "ranking_cols = [x for x in list(cols) if '_' in x]\n",
    "q_col = [x for x in list(cols) if 'Q' in x and '_' not in x and 'Q1'!=x]\n",
    "questions = results[ranking_cols].T\n",
    "\n",
    "# # # query+map should be diff\n",
    "questions = questions.reset_index()\n",
    "questions['query']=questions[0].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "#questions['index']=questions['index'].apply(lambda x: x[:x.index('_')])\n",
    "query_map = questions[['index','query']]\n",
    "\n",
    "col_results = results[ranking_cols].T\n",
    "\n",
    "col_results.columns = ['question','id','ranking']\n",
    "col_results = col_results.reset_index()\n",
    "col_results['quote']=col_results['question'].apply(lambda x: x[x.index('-')+2:])\n",
    "# col_results['index'] = col_results['index'].apply(lambda x: x[:x.index('_')])\n",
    "# col_results['query']=col_results['question'].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "# result = questions_ids.merge(col_results[['query','quote','ranking']],on=['query','quote'],how='left')\n",
    "# result['ranking'].isna().sum()\n",
    "# result['ranking']=result['ranking'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n",
      "/var/folders/r0/2fgtj8y934zddv46dgfbq1xw0000gn/T/ipykernel_2018/3448903697.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result['ranking']=result['ranking'].fillna(-1)\n"
     ]
    }
   ],
   "source": [
    "week1 =get_results_df(results_path='Evaluation/Results/day1_skyeler_only.csv',questions_path='Evaluation/day_1_data.csv')\n",
    "week2 =get_results_df(results_path='Evaluation/Results/day2_skyeler_only.csv',questions_path='Evaluation/day_2_data.csv')\n",
    "week3 =get_results_df(results_path='Evaluation/Results/day3_skyeler_only.csv',questions_path='Evaluation/day_3_data.csv')\n",
    "week4 =get_results_df(results_path='Evaluation/Results/day4_skyeler_only.csv',questions_path='Evaluation/day_4_data.csv')\n",
    "week5 =get_results_df(results_path='Evaluation/Results/day5_skyeler_only.csv',questions_path='Evaluation/day_5_data.csv')\n",
    "week6 =get_results_df(results_path='Evaluation/Results/day6_skyeler_only.csv',questions_path='Evaluation/day_6_data.csv')\n",
    "week7 =get_results_df(results_path='Evaluation/Results/day7_skyeler_only.csv',questions_path='Evaluation/day_7_data.csv')\n",
    "week8 =get_results_df(results_path='Evaluation/Results/day8_skyeler_only.csv',questions_path='Evaluation/day_8_data.csv')\n",
    "week9 =get_results_df(results_path='Evaluation/Results/day9_skyeler_only.csv',questions_path='Evaluation/day_9_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>quote</th>\n",
       "      <th>query</th>\n",
       "      <th>bm25</th>\n",
       "      <th>prevbm25</th>\n",
       "      <th>nextbm25</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113689</td>\n",
       "      <td>TIMICIN: No. We've... we've said our good-byes...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113558</td>\n",
       "      <td>LWAXANA: I agree. How about letting everybody ...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113532</td>\n",
       "      <td>LWAXANA: I'm not sure. A minute. An hour. \\n T...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55180</td>\n",
       "      <td>ODO: Marry me, Lwaxana... let me into your lig...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>8.857818</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55060</td>\n",
       "      <td>ODO: I'm sorry if I made you feel unwelcome......</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>112533</td>\n",
       "      <td>TROI: Sometimes... even when a victim has deal...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.63639</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>109313</td>\n",
       "      <td>WORF: But what do the Pakleds want? \\n RIKER: ...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>108851</td>\n",
       "      <td>BORG: We have analyzed your defensive capabili...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>105620</td>\n",
       "      <td>TROI: Where's Lieutenant Monroe? \\n O'BRIEN: C...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>105614</td>\n",
       "      <td>MONROE: All decks brace for--- \\n O'BRIEN: Cou...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2461 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indices                                              quote      query  \\\n",
       "0     113689  TIMICIN: No. We've... we've said our good-byes...    lwaxana   \n",
       "1     113558  LWAXANA: I agree. How about letting everybody ...    lwaxana   \n",
       "2     113532  LWAXANA: I'm not sure. A minute. An hour. \\n T...    lwaxana   \n",
       "3      55180  ODO: Marry me, Lwaxana... let me into your lig...    lwaxana   \n",
       "4      55060  ODO: I'm sorry if I made you feel unwelcome......    lwaxana   \n",
       "..       ...                                                ...        ...   \n",
       "257   112533  TROI: Sometimes... even when a victim has deal...  counselor   \n",
       "258   109313  WORF: But what do the Pakleds want? \\n RIKER: ...  counselor   \n",
       "259   108851  BORG: We have analyzed your defensive capabili...  counselor   \n",
       "260   105620  TROI: Where's Lieutenant Monroe? \\n O'BRIEN: C...  counselor   \n",
       "261   105614  MONROE: All decks brace for--- \\n O'BRIEN: Cou...  counselor   \n",
       "\n",
       "          bm25  prevbm25  nextbm25  ranking  \n",
       "0    12.436612  0.000000   0.00000       -1  \n",
       "1    12.436612  0.000000   0.00000       -1  \n",
       "2    12.436612  0.000000   0.00000       -1  \n",
       "3    12.436612  8.857818   0.00000       -1  \n",
       "4    12.436612  0.000000   0.00000       -1  \n",
       "..         ...       ...       ...      ...  \n",
       "257   8.975723  0.000000   4.63639       -1  \n",
       "258   8.975723  0.000000   0.00000       -1  \n",
       "259   8.975723  0.000000   0.00000       -1  \n",
       "260   8.975723  0.000000   0.00000       -1  \n",
       "261   8.975723  0.000000   0.00000       -1  \n",
       "\n",
       "[2461 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_eval_data = pd.concat([week9,week8,week7,week6, week5,week4,week3,week2,week1])\n",
    "# combined_eval_data.to_csv('skyeler_ranking_data.csv')\n",
    "combined_eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COME BACK & FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('skyeler_ranking_data_correct.csv',index_col=0)[['indices','ranking','query']]\n",
    "combined_eval_data.drop(columns=['ranking']).merge(temp,on=['indices','query'],how='left').to_csv('skyeler_ranking_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2461.0\n",
       "mean       -1.0\n",
       "std         0.0\n",
       "min        -1.0\n",
       "25%        -1.0\n",
       "50%        -1.0\n",
       "75%        -1.0\n",
       "max        -1.0\n",
       "Name: ranking, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_eval_data['ranking']=combined_eval_data['ranking'].apply(lambda x: int(x))\n",
    "combined_eval_data.ranking.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
