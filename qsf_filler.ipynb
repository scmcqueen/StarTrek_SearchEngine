{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Write Qualtrics Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simple_search_func as ss\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the qsf!\n",
    "#with open('Query_Template.qsf', 'r') as file:\n",
    "with open('Query_Template.qsf', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_dict = {\n",
    "    'love': ['hello', 'hi', 'are you', 'darling', 'sweetheart', 'honey', 'romance', 'affection', 'passion', 'devotion', \n",
    "             'adore', 'cherish', 'fondness', 'embrace', 'beloved', 'cuddle', 'valentine', 'kiss', 'heart', 'soulmate'],\n",
    "    'sadness': ['meow', 'meow meow', 'meowwww', 'tears', 'gloom', 'despair', 'melancholy', 'sorrow', 'blue', 'grief', \n",
    "                'heartache', 'mourn', 'loneliness', 'misery', 'pain', 'regret', 'weep', 'hurt', 'lost', 'downcast'],\n",
    "    'kiss': ['smoocher', 'kombucher', 'peck', 'smooch', 'liplock', 'mwah', 'pucker', 'osculation', 'romantic', 'passionate',\n",
    "             'sweet', 'gentle', 'soft', 'warm', 'butterfly', 'cheek', 'forehead', 'eskimo', 'lovebite', 'chaste'],\n",
    "    'happiness': ['joy', 'smile', 'laughter', 'cheer', 'delight', 'bliss', 'glee', 'ecstatic', 'merry', 'euphoria', \n",
    "                  'sunny', 'content', 'radiant', 'jubilant', 'bubbly', 'grateful', 'optimistic', 'carefree', 'vivacious', 'buoyant'],\n",
    "    'anger': ['rage', 'fury', 'wrath', 'outrage', 'resentment', 'bitterness', 'spite', 'grudge', 'irritation', 'annoyance',\n",
    "              'exasperation', 'hostility', 'hatred', 'indignation', 'fuming', 'seething', 'mad', 'infuriated', 'irate', 'tempest'],\n",
    "    'fear': ['terror', 'panic', 'dread', 'fright', 'horror', 'alarm', 'anxiety', 'nervous', 'uneasy', 'apprehension',\n",
    "             'timid', 'startle', 'tremble', 'phobia', 'shiver', 'quiver', 'spooked', 'petrified', 'chill', 'paranoia'],\n",
    "    'surprise': ['shock', 'amazement', 'astonishment', 'wonder', 'startled', 'stunned', 'flabbergasted', 'aghast', 'dumbfounded', 'jolted',\n",
    "                 'marvel', 'unexpected', 'perplexed', 'bewildered', 'gobsmacked', 'astounded', 'overwhelmed', 'speechless', 'baffled', 'staggered'],\n",
    "    'friendship': ['bond', 'companion', 'ally', 'trust', 'loyal', 'camaraderie', 'mate', 'bro', 'sisterhood', 'brotherhood',\n",
    "                   'affection', 'partnership', 'support', 'understanding', 'team', 'respect', 'connect', 'harmony', 'together', 'kindred'],\n",
    "    'jealousy': ['envy', 'resent', 'covet', 'green-eyed', 'possessive', 'suspicion', 'mistrust', 'distrust', 'bitterness', 'spite',\n",
    "                 'comparison', 'insecurity', 'longing', 'competitiveness', 'inferiority', 'grudge', 'fuming', 'anger', 'watchful', 'wary'],\n",
    "    'nostalgia': ['memories', 'past', 'bittersweet', 'longing', 'reminisce', 'yearning', 'flashback', 'old days', 'sentimental', 'melancholy',\n",
    "                  'childhood', 'throwback', 'wistful', 'retro', 'antique', 'classic', 'golden days', 'vintage', 'heartwarming', 'timeless'],\n",
    "    'fear2': ['terror', 'panic', 'dread', 'fright', 'horror', 'alarm', 'anxiety', 'nervous', 'uneasy', 'apprehension',\n",
    "             'timid', 'startle', 'tremble', 'phobia', 'shiver', 'quiver', 'spooked', 'petrified', 'chill', 'paranoia'],\n",
    "    'surprise2': ['shock', 'amazement', 'astonishment', 'wonder', 'startled', 'stunned', 'flabbergasted', 'aghast', 'dumbfounded', 'jolted',\n",
    "                 'marvel', 'unexpected', 'perplexed', 'bewildered', 'gobsmacked', 'astounded', 'overwhelmed', 'speechless', 'baffled', 'staggered'],\n",
    "    'friendship2': ['bond', 'companion', 'ally', 'trust', 'loyal', 'camaraderie', 'mate', 'bro', 'sisterhood', 'brotherhood',\n",
    "                   'affection', 'partnership', 'support', 'understanding', 'team', 'respect', 'connect', 'harmony', 'together', 'kindred'],\n",
    "    'jealousy2': ['envy', 'resent', 'covet', 'green-eyed', 'possessive', 'suspicion', 'mistrust', 'distrust', 'bitterness', 'spite',\n",
    "                 'comparison', 'insecurity', 'longing', 'competitiveness', 'inferiority', 'grudge', 'fuming', 'anger', 'watchful', 'wary'],\n",
    "    'nostalgia2': ['memories', 'past', 'bittersweet', 'longing', 'reminisce', 'yearning', 'flashback', 'old days', 'sentimental', 'melancholy',\n",
    "                  'childhood', 'throwback', 'wistful', 'retro', 'antique', 'classic', 'golden days', 'vintage', 'heartwarming', 'timeless']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(choices_dict.keys())# will be dict keys\n",
    "counter = 0\n",
    "next_topic=None\n",
    "\n",
    "\n",
    "# iterate\n",
    "for x in data['SurveyElements']:\n",
    "    if type(x['Payload']) != dict:\n",
    "        continue\n",
    "    if 'QuestionType' not in x['Payload'].keys():\n",
    "        continue\n",
    "    if x['Payload']['QuestionType']=='MC': # group rank, influences others\n",
    "        text = topics[counter]\n",
    "        old_text = x['SecondaryAttribute']\n",
    "        new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "        x['Payload']['QuestionDescription']= new_q\n",
    "        x['SecondaryAttribute'] = new_q\n",
    "        x['Payload']['QuestionText']= new_q\n",
    "        choices = choices_dict[text]\n",
    "        new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "        x['Payload']['Choices']=new_choices\n",
    "        x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        counter +=1\n",
    "counter = 0\n",
    "for x in data['SurveyElements']:\n",
    "    if type(x['Payload']) != dict:\n",
    "        continue\n",
    "    if 'QuestionType' not in x['Payload'].keys():\n",
    "        continue\n",
    "    if x['Payload']['QuestionType']=='RO': # rank only, depends on other\n",
    "        # THIS COMES FIRST\n",
    "        # update Secondary Attribute: replace whatever is in \"\"\n",
    "        text = topics[counter]\n",
    "        next_topic = text\n",
    "        old_text = x['SecondaryAttribute']\n",
    "        new_q = f'Rank these quotes on how funny they are!'\n",
    "        x['SecondaryAttribute'] = new_q\n",
    "        # update ['Payload']['QuestionText'] replace whatever is in \"\"\n",
    "        x['Payload']['QuestionText']= new_q\n",
    "        x['Payload']['QuestionDescription']= new_q\n",
    "        counter+=1\n",
    "        #counter +=1\n",
    "\n",
    "# save\n",
    "with open('test.qsf', 'w') as json_file:\n",
    "    json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a function\n",
    "\n",
    "def new_survey_file(choices_dict:dict,file_name:str,template_name:str='Query_Template.qsf'):\n",
    "    with open(template_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    topics = list(choices_dict.keys())# will be dict keys\n",
    "    c_topics = topics.copy()\n",
    "    # surveyid = 'newstring'\n",
    "\n",
    "    # iterate\n",
    "    for x in data['SurveyElements']:\n",
    "        if type(x['Payload']) != dict:\n",
    "            continue\n",
    "        if 'QuestionType' not in x['Payload'].keys():\n",
    "            continue\n",
    "        # x['SurveyID']= surveyid\n",
    "        if x['Payload']['QuestionType']=='MC': # group rank, influences others\n",
    "            text = topics.pop()\n",
    "            new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            choices = choices_dict[text]\n",
    "            new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "            x['Payload']['Choices']=new_choices\n",
    "            x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        if x['Payload']['QuestionType']=='RO': # rank only, depends on other\n",
    "            # update Secondary Attribute: replace whatever is in \"\"\n",
    "            text = c_topics.pop()\n",
    "            new_q = f'Rank these quotes on how funny they are!'\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            # update ['Payload']['QuestionText'] replace whatever is in \"\"\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "\n",
    "    # save\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up examples\n",
    "\n",
    "Now that I have the function written, I need to load up the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 0 documents. The engine now has 144211 documents.\n",
      "Complete data added.\n"
     ]
    }
   ],
   "source": [
    "# load up that search\n",
    "complete = pd.read_csv('https://scmcqueen.github.io/StarTrekScriptData/complete_data.csv')\n",
    "complete.columns = ['index','character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']\n",
    "complete['quote']=complete['quote'].apply(lambda text: \" \".join(text.split()))\n",
    "complete['character']=complete['character'].fillna('NA')\n",
    "test_engine = ss.search_engine()\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])\n",
    "test_engine.add_df(complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=test_engine.bw_search('candle',30)\n",
    "search_results = test_engine.pretty_print([x[0] for x in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [x[0] for x in results]\n",
    "choices = [' '.join(x) for x in search_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "choices = []\n",
    "search_term = []\n",
    "file_input = {}\n",
    "\n",
    "for term in keywords_1:\n",
    "    # do the search\n",
    "    results=test_engine.bw_search(term,20)\n",
    "    search_results = test_engine.pretty_print([x[0] for x in results])\n",
    "    # update values\n",
    "    t_ind = [x[0] for x in results]\n",
    "    t_choices = [' '.join(x) for x in search_results]\n",
    "    t_search = [term]*len(t_ind)\n",
    "    # update big list\n",
    "    indices+=t_ind\n",
    "    choices+=t_choices\n",
    "    search_term+=t_search\n",
    "    # update the dict\n",
    "    file_input[term] = t_choices  \n",
    "\n",
    "new_survey_file(choices_dict=file_input,file_name='Evaluation/day_1.qsf',template_name='Query_Template.qsf')\n",
    "pd.DataFrame({'indices':indices,'choices':choices,'search':search_term}).to_csv('Evaluation/day_1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity',\n",
    "               'story', 'religion', 'child', 'molly','counselor']\n",
    "keywords_2 =  ['archaeology','chateau','trial','fiction','romance','wedding','father','kahless','chocolate','future',\n",
    "               'bridge','saucer','coffee','romulans','colony']\n",
    "keywords_3 =  ['raktajino','commit no errors','tanagra','borg','cardassia','poetry','spot','assimilate','unusual','barclay',\n",
    "               'acquisition','rules','vedek','warp crystal',\"bat'leth\"]\n",
    "keywords_4 =  ['blood wine','gagh','cook','celebrate','impossible','earl grey','jake','geordi','riker','poker',\n",
    "               'phaser','occupation','conscious minds','tailor','neutral zone']\n",
    "keywords_5 =  ['men','women','miles','worf','bashir','commander','captain','kira','troi','guinan',\n",
    "               'shields','unification','mister spock','tribble','android']\n",
    "keywords_6 =  ['unraveled','friendship','hailing frequencies','universe','traveler','wesley','good tea','good book','make it so','flute',\n",
    "               'neutrino levels','noonian soong','breen','evidence','vacation']\n",
    "keywords_7 =  ['memory','merry man','obedient','honor','san francisco','new orleans','liberation','imagination','maquis','tribunal',\n",
    "               'trill','lore','risa','detective','ezri']\n",
    "keywords_8 =  ['not picard','ice cream','morn','weyoun','dukat','civilization','replicators','truth','lunch','past',\n",
    "               'empath','betray','warp bubble','jadzia','pregnant']\n",
    "keywords_9 =  ['vineyard','lwaxana','bucket','justice is justice','espionage','same lie','mother','klingon','baseball','moriarty',\n",
    "               'vulcan','moon','lower decks','the academy','full impulse']\n",
    "keywords_10 =  ['enterprise','ferengi','nagus','death','root beer','alpha quadrant','wormhole','tasha','holosuite','holmes',\n",
    "                'the defiant','ensign ro','dabo girl','secret agent','oo-mox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {1:keywords_1,\n",
    "            2:keywords_2,\n",
    "            3:keywords_3,\n",
    "            4:keywords_4,\n",
    "            5:keywords_5,\n",
    "            6:keywords_6,\n",
    "            7:keywords_7,\n",
    "            8:keywords_8,\n",
    "            9:keywords_9,\n",
    "            10:keywords_10\n",
    "            }\n",
    "\n",
    "for x in keywords.keys():\n",
    "    counter = str(x)\n",
    "    t_keys = keywords[x]\n",
    "\n",
    "    indices = []\n",
    "    choices = []\n",
    "    search_term = []\n",
    "    file_input = {}\n",
    "\n",
    "    for term in t_keys:\n",
    "        # do the search\n",
    "        results=test_engine.bw_search(term,20)\n",
    "        search_results = test_engine.pretty_print([x[0] for x in results])\n",
    "        # update values\n",
    "        t_ind = [x[0] for x in results]\n",
    "        t_choices = [' '.join(x) for x in search_results]\n",
    "        t_search = [term]*len(t_ind)\n",
    "        # update big list\n",
    "        indices+=t_ind\n",
    "        choices+=t_choices\n",
    "        search_term+=t_search\n",
    "        # update the dict\n",
    "        file_input[term] = t_choices\n",
    "\n",
    "    new_survey_file(choices_dict=file_input,file_name=f'Evaluation/day_{counter}.qsf',template_name='Query_Template.qsf')\n",
    "    pd.DataFrame({'indices':indices,'choices':choices,'search':search_term}).to_csv(f'Evaluation/day_{counter}_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(results_path:str='Evaluation/Results/day2_skyeler_only.tsv',questions_path:str='Evaluation/day_2_data.csv'):\n",
    "    # start by reading a file\n",
    "\n",
    "    results = pd.read_csv(results_path)\n",
    "    questions_ids = pd.read_csv(questions_path)\n",
    "    questions_ids.columns = ['Unnamed: 0', 'indices', 'quote', 'query']\n",
    "    results =results.drop(columns=['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage'])\n",
    "    cols = results.columns\n",
    "\n",
    "    ranking_cols = [x for x in list(cols) if '_' in x]\n",
    "    q_col = [x for x in list(cols) if 'Q' in x and '_' not in x and 'Q1'!=x]\n",
    "    questions = results[ranking_cols].T\n",
    "\n",
    "    # # query+map should be diff\n",
    "    questions = questions.reset_index()\n",
    "    questions['query']=questions[0].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "    questions['index']=questions['index'].apply(lambda x: x[:x.index('_')])\n",
    "    query_map = questions[['index','query']]\n",
    "\n",
    "    col_results = results[ranking_cols].T\n",
    "\n",
    "    col_results.columns = ['question','id','ranking']\n",
    "    col_results = col_results.reset_index()\n",
    "    col_results['quote']=col_results['question'].apply(lambda x: x[x.index('-')+2:])\n",
    "    col_results['index'] = col_results['index'].apply(lambda x: x[:x.index('_')])\n",
    "    col_results['query']=col_results['question'].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "    result = questions_ids.merge(col_results[['query','quote','ranking']],on=['query','quote'],how='left')\n",
    "    result['ranking']=result['ranking'].fillna(-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "week2 =get_results_df(results_path='Evaluation/Results/day2_skyeler_only.csv',questions_path='Evaluation/day_2_data.csv')\n",
    "week3 =get_results_df(results_path='Evaluation/Results/day3_skyeler_only.csv',questions_path='Evaluation/day_3_data.csv')\n",
    "week4 =get_results_df(results_path='Evaluation/Results/day4_skyeler_only.csv',questions_path='Evaluation/day_4_data.csv')\n",
    "week5 =get_results_df(results_path='Evaluation/Results/day5_skyeler_only.csv',questions_path='Evaluation/day_5_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>indices</th>\n",
       "      <th>quote</th>\n",
       "      <th>query</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66191</td>\n",
       "      <td>QUARK: Who? LARELL: Two men. QUARK: Brothers?</td>\n",
       "      <td>men</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>120092</td>\n",
       "      <td>BRENNA: You may have all the time in the world...</td>\n",
       "      <td>men</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46258</td>\n",
       "      <td>SARINA: Why are you pretending that it's not t...</td>\n",
       "      <td>men</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60897</td>\n",
       "      <td>KEEVAN: I'm going to order the Jem'Hadar to at...</td>\n",
       "      <td>men</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1085</td>\n",
       "      <td>PABST: People won't accept it. It's not believ...</td>\n",
       "      <td>men</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>95494</td>\n",
       "      <td>GOSHEVEN: Hyperonic radiation took the lives o...</td>\n",
       "      <td>colony</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>110032</td>\n",
       "      <td>PICARD: It could have been damaged by the expl...</td>\n",
       "      <td>colony</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>102026</td>\n",
       "      <td>WORF: Sir... the disturbance on Melona is beco...</td>\n",
       "      <td>colony</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>101997</td>\n",
       "      <td>WORF: I can't tell. We are still too far away....</td>\n",
       "      <td>colony</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>75678</td>\n",
       "      <td>WORF: Yes. But you must realize... I am no lon...</td>\n",
       "      <td>colony</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1133 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  indices                                              quote  \\\n",
       "0             0    66191      QUARK: Who? LARELL: Two men. QUARK: Brothers?   \n",
       "1             1   120092  BRENNA: You may have all the time in the world...   \n",
       "2             2    46258  SARINA: Why are you pretending that it's not t...   \n",
       "3             3    60897  KEEVAN: I'm going to order the Jem'Hadar to at...   \n",
       "4             4     1085  PABST: People won't accept it. It's not believ...   \n",
       "..          ...      ...                                                ...   \n",
       "259         259    95494  GOSHEVEN: Hyperonic radiation took the lives o...   \n",
       "260         260   110032  PICARD: It could have been damaged by the expl...   \n",
       "261         261   102026  WORF: Sir... the disturbance on Melona is beco...   \n",
       "262         262   101997  WORF: I can't tell. We are still too far away....   \n",
       "263         263    75678  WORF: Yes. But you must realize... I am no lon...   \n",
       "\n",
       "      query ranking  \n",
       "0       men      -1  \n",
       "1       men       5  \n",
       "2       men       1  \n",
       "3       men      -1  \n",
       "4       men      -1  \n",
       "..      ...     ...  \n",
       "259  colony       4  \n",
       "260  colony      -1  \n",
       "261  colony      -1  \n",
       "262  colony      -1  \n",
       "263  colony      -1  \n",
       "\n",
       "[1133 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_eval_data = pd.concat([week5,week4,week3,week2])\n",
    "# combined_eval_data.to_csv('skyeler_ranking_data.csv')\n",
    "combined_eval_data\n",
    "# NEED TO DO WEEK1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
