{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Write Qualtrics Surveys\n",
    "\n",
    "This notebook writes the Qualtrics survey forms and then reads the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import search_engine as ss\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the qsf!\n",
    "with open('Query_Template.qsf', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function to write survey file\n",
    "\n",
    "def new_survey_file(choices_dict:dict,file_name:str,template_name:str='Query_Template.qsf')->None:\n",
    "    '''Writes a survey file with the given choices.\n",
    "\n",
    "    Input:\n",
    "        choices_dict: dict, with search result choices\n",
    "        file_name: str, name of the file to save\n",
    "        template_name: str, name of the query template\n",
    "\n",
    "    Output:\n",
    "        None, a file is saved\n",
    "    '''\n",
    "    # open the template\n",
    "    with open(template_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    topics = list(choices_dict.keys()) # will be dict keys\n",
    "    c_topics = topics.copy()\n",
    "\n",
    "    # iterate through the survey to get to the questions\n",
    "    for x in data['SurveyElements']:\n",
    "        if type(x['Payload']) != dict: # if there's no payload (questions) skip\n",
    "            continue\n",
    "        if 'QuestionType' not in x['Payload'].keys(): # if there's no question in the payload, skip\n",
    "            continue\n",
    "        # if it is MC, then we choose if the choices are relevant\n",
    "        if x['Payload']['QuestionType']=='MC':\n",
    "            text = topics.pop()\n",
    "            new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            choices = choices_dict[text]\n",
    "            new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "            x['Payload']['Choices']=new_choices\n",
    "            x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        # if it is RO, then we rank and order the selected results\n",
    "        if x['Payload']['QuestionType']=='RO':\n",
    "            text = c_topics.pop()\n",
    "            new_q = f'Rank these quotes on how funny they are!'\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "\n",
    "    # save\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up examples\n",
    "\n",
    "Now that I have the function written, I need to load up the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We added 144211 documents. The engine now has 144211 documents.\n"
     ]
    }
   ],
   "source": [
    "# load up that search\n",
    "complete = pd.read_csv('https://scmcqueen.github.io/StarTrekScriptData/complete_data.csv')\n",
    "complete.columns = ['index','character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']\n",
    "complete['quote']=complete['quote'].apply(lambda text: \" \".join(text.split()))\n",
    "complete['character']=complete['character'].fillna('NA')\n",
    "\n",
    "# create instance of the search engine\n",
    "test_engine = ss.search_engine(name='BM25 Engine',full_data=complete)\n",
    "# load data in bulk\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample results\n",
    "results=test_engine.bw_search('candle',20,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set keywords\n",
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "choices = []\n",
    "search_term = []\n",
    "bm25 = [] # new\n",
    "bm25_prev = []\n",
    "bm25_next = []\n",
    "file_input = {}\n",
    "\n",
    "for term in keywords_1:\n",
    "    # do the search\n",
    "    results=test_engine.bw_search(term,20,True)\n",
    "    search_results = test_engine.old_pretty_print([x[0] for x in results])\n",
    "    # update values\n",
    "    t_ind = [x[0] for x in results]\n",
    "    t_choices = [' '.join(x) for x in search_results]\n",
    "    t_search = [term]*len(t_ind)\n",
    "    # update big list\n",
    "    indices+=t_ind\n",
    "    choices+=t_choices\n",
    "    search_term+=t_search\n",
    "    bm25 +=[x[1] for x in results]\n",
    "    bm25_prev +=[x[2] for x in results]\n",
    "    bm25_next +=[x[3] for x in results]\n",
    "    # update the dict\n",
    "    file_input[term] = t_choices  \n",
    "\n",
    "# don't need to save now\n",
    "# new_survey_file(choices_dict=file_input,file_name='Evaluation/day_1.qsf',template_name='Query_Template.qsf')\n",
    "pd.DataFrame({'indices':indices,'choices':choices,'search':search_term,'bm25':bm25,'prev_bm25':bm25_prev,'next_bm25':bm25_next}).to_csv('Evaluation/day_1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>choices</th>\n",
       "      <th>search</th>\n",
       "      <th>bm25</th>\n",
       "      <th>prev_bm25</th>\n",
       "      <th>next_bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44542</td>\n",
       "      <td>JOSEPH: He stole a candle. O'BRIEN: One candle...</td>\n",
       "      <td>candle</td>\n",
       "      <td>14.147200</td>\n",
       "      <td>13.037027</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44541</td>\n",
       "      <td>O'BRIEN: What did he do to deserve this? JOSEP...</td>\n",
       "      <td>candle</td>\n",
       "      <td>13.037027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112905</td>\n",
       "      <td>TROI: Many things improve with age... maybe yo...</td>\n",
       "      <td>candle</td>\n",
       "      <td>11.491176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88378</td>\n",
       "      <td>BEVERLY: Computer, secure door. BEVERLY: I lit...</td>\n",
       "      <td>candle</td>\n",
       "      <td>11.378741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88194</td>\n",
       "      <td>QUINT: There's a lot of things she didn't tell...</td>\n",
       "      <td>candle</td>\n",
       "      <td>11.054260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>108760</td>\n",
       "      <td>Q: After our last encounter, I was asked to le...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>6.681643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>79522</td>\n",
       "      <td>\"Q\" : You show promise, my good fellow. PICARD...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>6.638868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>119412</td>\n",
       "      <td>GEORDI: I'll be honest with you. We don't know...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>6.354117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>140566</td>\n",
       "      <td>TROI: Feelings aren't positive or negative Dat...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>5.952888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>96655</td>\n",
       "      <td>DATA: The moon's altitude is fifty-five thousa...</td>\n",
       "      <td>humanity</td>\n",
       "      <td>5.952888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indices                                            choices    search  \\\n",
       "0      44542  JOSEPH: He stole a candle. O'BRIEN: One candle...    candle   \n",
       "1      44541  O'BRIEN: What did he do to deserve this? JOSEP...    candle   \n",
       "2     112905  TROI: Many things improve with age... maybe yo...    candle   \n",
       "3      88378  BEVERLY: Computer, secure door. BEVERLY: I lit...    candle   \n",
       "4      88194  QUINT: There's a lot of things she didn't tell...    candle   \n",
       "..       ...                                                ...       ...   \n",
       "172   108760  Q: After our last encounter, I was asked to le...  humanity   \n",
       "173    79522  \"Q\" : You show promise, my good fellow. PICARD...  humanity   \n",
       "174   119412  GEORDI: I'll be honest with you. We don't know...  humanity   \n",
       "175   140566  TROI: Feelings aren't positive or negative Dat...  humanity   \n",
       "176    96655  DATA: The moon's altitude is fifty-five thousa...  humanity   \n",
       "\n",
       "          bm25  prev_bm25  next_bm25  \n",
       "0    14.147200  13.037027     0.0000  \n",
       "1    13.037027   0.000000    14.1472  \n",
       "2    11.491176   0.000000     0.0000  \n",
       "3    11.378741   0.000000     0.0000  \n",
       "4    11.054260   0.000000     0.0000  \n",
       "..         ...        ...        ...  \n",
       "172   6.681643   0.000000     0.0000  \n",
       "173   6.638868   0.000000     0.0000  \n",
       "174   6.354117   0.000000     0.0000  \n",
       "175   5.952888   0.000000     0.0000  \n",
       "176   5.952888   0.000000     0.0000  \n",
       "\n",
       "[177 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data frame\n",
    "pd.DataFrame({'indices':indices,'choices':choices,'search':search_term,'bm25':bm25,'prev_bm25':bm25_prev,'next_bm25':bm25_next})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all of the keywords\n",
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity',\n",
    "               'story', 'religion', 'child', 'molly','counselor']\n",
    "keywords_2 =  ['archaeology','chateau','trial','fiction','romance','wedding','father','kahless','chocolate','future',\n",
    "               'bridge','saucer','coffee','romulans','colony']\n",
    "keywords_3 =  ['raktajino','commit no errors','tanagra','borg','cardassia','poetry','spot','assimilate','unusual','barclay',\n",
    "               'acquisition','rules','vedek','warp crystal',\"bat'leth\"]\n",
    "keywords_4 =  ['blood wine','gagh','cook','celebrate','impossible','earl grey','jake','geordi','riker','poker',\n",
    "               'phaser','occupation','conscious minds','tailor','neutral zone']\n",
    "keywords_5 =  ['men','women','miles','worf','bashir','commander','captain','kira','troi','guinan',\n",
    "               'shields','unification','mister spock','tribble','android']\n",
    "keywords_6 =  ['unraveled','friendship','hailing frequencies','universe','traveler','wesley','good tea','good book','make it so','flute',\n",
    "               'neutrino levels','noonian soong','breen','evidence','vacation']\n",
    "keywords_7 =  ['memory','merry man','obedient','honor','san francisco','new orleans','liberation','imagination','maquis','tribunal',\n",
    "               'trill','lore','risa','detective','ezri']\n",
    "keywords_8 =  ['not picard','ice cream','morn','weyoun','dukat','civilization','replicators','truth','lunch','past',\n",
    "               'empath','betray','warp bubble','jadzia','pregnant']\n",
    "keywords_9 =  ['vineyard','lwaxana','bucket','justice is justice','espionage','same lie','mother','klingon','baseball','moriarty',\n",
    "               'vulcan','moon','lower decks','the academy','full impulse']\n",
    "keywords_10 =  ['enterprise','ferengi','nagus','death','root beer','alpha quadrant','wormhole','tasha','holosuite','holmes',\n",
    "                'the defiant','ensign ro','dabo girl','secret agent','oo-mox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different survey files for all of the different weeks\n",
    "\n",
    "keywords = {1:keywords_1,\n",
    "            2:keywords_2,\n",
    "            3:keywords_3,\n",
    "            4:keywords_4,\n",
    "            5:keywords_5,\n",
    "            6:keywords_6,\n",
    "            7:keywords_7,\n",
    "            8:keywords_8,\n",
    "            9:keywords_9,\n",
    "            10:keywords_10\n",
    "            }\n",
    "\n",
    "for x in keywords.keys():\n",
    "    counter = str(x)\n",
    "    t_keys = keywords[x]\n",
    "\n",
    "    indices = []\n",
    "    choices = []\n",
    "    search_term = []\n",
    "    bm25 = [] # new\n",
    "    bm25_prev = []\n",
    "    bm25_next = []\n",
    "    file_input = {}\n",
    "\n",
    "    for term in t_keys:\n",
    "        # do the search\n",
    "        results=test_engine.bw_search(term,20,True)\n",
    "        search_results = test_engine.old_pretty_print([x[0] for x in results])\n",
    "        # update values\n",
    "        t_ind = [x[0] for x in results]\n",
    "        t_choices = [' '.join(x) for x in search_results]\n",
    "        #t_choices = [test_engine.pretty_print(x[0]) for x in results]\n",
    "        t_search = [term]*len(t_ind)\n",
    "        # update big list\n",
    "        indices+=t_ind\n",
    "        choices+=t_choices\n",
    "        search_term+=t_search\n",
    "        bm25 +=[x[1] for x in results]\n",
    "        bm25_prev +=[x[2] for x in results]\n",
    "        bm25_next +=[x[3] for x in results]\n",
    "        # update the dict\n",
    "        file_input[term] = t_choices\n",
    "\n",
    "    #new_survey_file(choices_dict=file_input,file_name=f'Evaluation/day_{counter}.qsf',template_name='Query_Template.qsf')\n",
    "    pd.DataFrame({'indices':indices,'choices':choices,'search':search_term,'bm25':bm25,'prev_bm25':bm25_prev,'next_bm25':bm25_next}).to_csv(f'Evaluation/day_{counter}_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Results\n",
    "\n",
    "Now that the surveys have been filled out, we can read in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(results_path:str='Evaluation/Results/day2_skyeler_only.tsv',questions_path:str='Evaluation/day_2_data.csv'):\n",
    "    '''Read in Qualtrics Survey results.\n",
    "\n",
    "    Input:\n",
    "        results_path: str, path to the qualtrics survey results\n",
    "        questions_path: str, the path to the original questions csv\n",
    "\n",
    "    Output:\n",
    "        pd.DataFrame\n",
    "    '''\n",
    "\n",
    "    # start by reading files\n",
    "    results = pd.read_csv(results_path)\n",
    "    questions_ids = pd.read_csv(questions_path,index_col=0)\n",
    "    # format columns\n",
    "    questions_ids.columns = ['indices', 'quote', 'query','bm25','prevbm25','nextbm25']\n",
    "    # drop unneeded columns\n",
    "    results =results.drop(columns=['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage'])\n",
    "    cols = results.columns\n",
    "\n",
    "    # columns with needed data\n",
    "    ranking_cols = [x for x in list(cols) if '_' in x]\n",
    "    q_col = [x for x in list(cols) if 'Q' in x and '_' not in x and 'Q1'!=x]\n",
    "    questions = results[ranking_cols].T\n",
    "\n",
    "    # # query+map should be diff\n",
    "    questions = questions.reset_index()\n",
    "    questions['query']=questions[0].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "    questions['index']=questions['index'].apply(lambda x: x[:x.index('_')])\n",
    "    query_map = questions[['index','query']]\n",
    "\n",
    "    col_results = results[ranking_cols].T\n",
    "\n",
    "    col_results.columns = ['question','id','ranking']\n",
    "    col_results = col_results.reset_index()\n",
    "    col_results['quote']=col_results['question'].apply(lambda x: x[x.index('-')+2:])\n",
    "    col_results['index'] = col_results['index'].apply(lambda x: x[:x.index('_')])\n",
    "    col_results['query']=col_results['question'].apply(lambda x:re.findall(r\"'(.*?)'\", x)[0])\n",
    "    result = questions_ids.merge(col_results[['query','quote','ranking']],on=['query','quote'],how='left')\n",
    "    result['ranking']=result['ranking'].fillna(-1) # if not ranked (meaning irrelevant, give score of -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results\n",
    "week1 =get_results_df(results_path='Evaluation/Results/day1_skyeler_only.csv',questions_path='Evaluation/day_1_data.csv')\n",
    "week2 =get_results_df(results_path='Evaluation/Results/day2_skyeler_only.csv',questions_path='Evaluation/day_2_data.csv')\n",
    "week3 =get_results_df(results_path='Evaluation/Results/day3_skyeler_only.csv',questions_path='Evaluation/day_3_data.csv')\n",
    "week4 =get_results_df(results_path='Evaluation/Results/day4_skyeler_only.csv',questions_path='Evaluation/day_4_data.csv')\n",
    "week5 =get_results_df(results_path='Evaluation/Results/day5_skyeler_only.csv',questions_path='Evaluation/day_5_data.csv')\n",
    "week6 =get_results_df(results_path='Evaluation/Results/day6_skyeler_only.csv',questions_path='Evaluation/day_6_data.csv')\n",
    "week7 =get_results_df(results_path='Evaluation/Results/day7_skyeler_only.csv',questions_path='Evaluation/day_7_data.csv')\n",
    "week8 =get_results_df(results_path='Evaluation/Results/day8_skyeler_only.csv',questions_path='Evaluation/day_8_data.csv')\n",
    "week9 =get_results_df(results_path='Evaluation/Results/day9_skyeler_only.csv',questions_path='Evaluation/day_9_data.csv')\n",
    "week10 = get_results_df(results_path='Evaluation/Results/skyeler_day10.csv',questions_path='Evaluation/day_10_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>quote</th>\n",
       "      <th>query</th>\n",
       "      <th>bm25</th>\n",
       "      <th>prevbm25</th>\n",
       "      <th>nextbm25</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113689</td>\n",
       "      <td>TIMICIN: No. We've... we've said our good-byes...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113558</td>\n",
       "      <td>LWAXANA: I agree. How about letting everybody ...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113532</td>\n",
       "      <td>LWAXANA: I'm not sure. A minute. An hour. \\n T...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55180</td>\n",
       "      <td>ODO: Marry me, Lwaxana... let me into your lig...</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>8.857818</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55060</td>\n",
       "      <td>ODO: I'm sorry if I made you feel unwelcome......</td>\n",
       "      <td>lwaxana</td>\n",
       "      <td>12.436612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>112533</td>\n",
       "      <td>TROI: Sometimes... even when a victim has deal...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.63639</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>109313</td>\n",
       "      <td>WORF: But what do the Pakleds want? \\n RIKER: ...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>108851</td>\n",
       "      <td>BORG: We have analyzed your defensive capabili...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>105620</td>\n",
       "      <td>TROI: Where's Lieutenant Monroe? \\n O'BRIEN: C...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>105614</td>\n",
       "      <td>MONROE: All decks brace for--- \\n O'BRIEN: Cou...</td>\n",
       "      <td>counselor</td>\n",
       "      <td>8.975723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2461 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     indices                                              quote      query  \\\n",
       "0     113689  TIMICIN: No. We've... we've said our good-byes...    lwaxana   \n",
       "1     113558  LWAXANA: I agree. How about letting everybody ...    lwaxana   \n",
       "2     113532  LWAXANA: I'm not sure. A minute. An hour. \\n T...    lwaxana   \n",
       "3      55180  ODO: Marry me, Lwaxana... let me into your lig...    lwaxana   \n",
       "4      55060  ODO: I'm sorry if I made you feel unwelcome......    lwaxana   \n",
       "..       ...                                                ...        ...   \n",
       "257   112533  TROI: Sometimes... even when a victim has deal...  counselor   \n",
       "258   109313  WORF: But what do the Pakleds want? \\n RIKER: ...  counselor   \n",
       "259   108851  BORG: We have analyzed your defensive capabili...  counselor   \n",
       "260   105620  TROI: Where's Lieutenant Monroe? \\n O'BRIEN: C...  counselor   \n",
       "261   105614  MONROE: All decks brace for--- \\n O'BRIEN: Cou...  counselor   \n",
       "\n",
       "          bm25  prevbm25  nextbm25  ranking  \n",
       "0    12.436612  0.000000   0.00000       -1  \n",
       "1    12.436612  0.000000   0.00000       -1  \n",
       "2    12.436612  0.000000   0.00000       -1  \n",
       "3    12.436612  8.857818   0.00000       -1  \n",
       "4    12.436612  0.000000   0.00000       -1  \n",
       "..         ...       ...       ...      ...  \n",
       "257   8.975723  0.000000   4.63639       -1  \n",
       "258   8.975723  0.000000   0.00000       -1  \n",
       "259   8.975723  0.000000   0.00000       -1  \n",
       "260   8.975723  0.000000   0.00000       -1  \n",
       "261   8.975723  0.000000   0.00000       -1  \n",
       "\n",
       "[2461 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine data\n",
    "combined_eval_data = pd.concat([week10,week9,week8,week7,week6, week5,week4,week3,week2,week1])\n",
    "# save data\n",
    "# combined_eval_data.to_csv('skyeler_ranking_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
