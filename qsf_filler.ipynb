{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Write Qualtrics Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simple_search_func as ss\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the qsf!\n",
    "#with open('Query_Template.qsf', 'r') as file:\n",
    "with open('Query_Template.qsf', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices_dict = {\n",
    "    'love': ['hello', 'hi', 'are you', 'darling', 'sweetheart', 'honey', 'romance', 'affection', 'passion', 'devotion', \n",
    "             'adore', 'cherish', 'fondness', 'embrace', 'beloved', 'cuddle', 'valentine', 'kiss', 'heart', 'soulmate'],\n",
    "    'sadness': ['meow', 'meow meow', 'meowwww', 'tears', 'gloom', 'despair', 'melancholy', 'sorrow', 'blue', 'grief', \n",
    "                'heartache', 'mourn', 'loneliness', 'misery', 'pain', 'regret', 'weep', 'hurt', 'lost', 'downcast'],\n",
    "    'kiss': ['smoocher', 'kombucher', 'peck', 'smooch', 'liplock', 'mwah', 'pucker', 'osculation', 'romantic', 'passionate',\n",
    "             'sweet', 'gentle', 'soft', 'warm', 'butterfly', 'cheek', 'forehead', 'eskimo', 'lovebite', 'chaste'],\n",
    "    'happiness': ['joy', 'smile', 'laughter', 'cheer', 'delight', 'bliss', 'glee', 'ecstatic', 'merry', 'euphoria', \n",
    "                  'sunny', 'content', 'radiant', 'jubilant', 'bubbly', 'grateful', 'optimistic', 'carefree', 'vivacious', 'buoyant'],\n",
    "    'anger': ['rage', 'fury', 'wrath', 'outrage', 'resentment', 'bitterness', 'spite', 'grudge', 'irritation', 'annoyance',\n",
    "              'exasperation', 'hostility', 'hatred', 'indignation', 'fuming', 'seething', 'mad', 'infuriated', 'irate', 'tempest'],\n",
    "    'fear': ['terror', 'panic', 'dread', 'fright', 'horror', 'alarm', 'anxiety', 'nervous', 'uneasy', 'apprehension',\n",
    "             'timid', 'startle', 'tremble', 'phobia', 'shiver', 'quiver', 'spooked', 'petrified', 'chill', 'paranoia'],\n",
    "    'surprise': ['shock', 'amazement', 'astonishment', 'wonder', 'startled', 'stunned', 'flabbergasted', 'aghast', 'dumbfounded', 'jolted',\n",
    "                 'marvel', 'unexpected', 'perplexed', 'bewildered', 'gobsmacked', 'astounded', 'overwhelmed', 'speechless', 'baffled', 'staggered'],\n",
    "    'friendship': ['bond', 'companion', 'ally', 'trust', 'loyal', 'camaraderie', 'mate', 'bro', 'sisterhood', 'brotherhood',\n",
    "                   'affection', 'partnership', 'support', 'understanding', 'team', 'respect', 'connect', 'harmony', 'together', 'kindred'],\n",
    "    'jealousy': ['envy', 'resent', 'covet', 'green-eyed', 'possessive', 'suspicion', 'mistrust', 'distrust', 'bitterness', 'spite',\n",
    "                 'comparison', 'insecurity', 'longing', 'competitiveness', 'inferiority', 'grudge', 'fuming', 'anger', 'watchful', 'wary'],\n",
    "    'nostalgia': ['memories', 'past', 'bittersweet', 'longing', 'reminisce', 'yearning', 'flashback', 'old days', 'sentimental', 'melancholy',\n",
    "                  'childhood', 'throwback', 'wistful', 'retro', 'antique', 'classic', 'golden days', 'vintage', 'heartwarming', 'timeless'],\n",
    "    'fear2': ['terror', 'panic', 'dread', 'fright', 'horror', 'alarm', 'anxiety', 'nervous', 'uneasy', 'apprehension',\n",
    "             'timid', 'startle', 'tremble', 'phobia', 'shiver', 'quiver', 'spooked', 'petrified', 'chill', 'paranoia'],\n",
    "    'surprise2': ['shock', 'amazement', 'astonishment', 'wonder', 'startled', 'stunned', 'flabbergasted', 'aghast', 'dumbfounded', 'jolted',\n",
    "                 'marvel', 'unexpected', 'perplexed', 'bewildered', 'gobsmacked', 'astounded', 'overwhelmed', 'speechless', 'baffled', 'staggered'],\n",
    "    'friendship2': ['bond', 'companion', 'ally', 'trust', 'loyal', 'camaraderie', 'mate', 'bro', 'sisterhood', 'brotherhood',\n",
    "                   'affection', 'partnership', 'support', 'understanding', 'team', 'respect', 'connect', 'harmony', 'together', 'kindred'],\n",
    "    'jealousy2': ['envy', 'resent', 'covet', 'green-eyed', 'possessive', 'suspicion', 'mistrust', 'distrust', 'bitterness', 'spite',\n",
    "                 'comparison', 'insecurity', 'longing', 'competitiveness', 'inferiority', 'grudge', 'fuming', 'anger', 'watchful', 'wary'],\n",
    "    'nostalgia2': ['memories', 'past', 'bittersweet', 'longing', 'reminisce', 'yearning', 'flashback', 'old days', 'sentimental', 'melancholy',\n",
    "                  'childhood', 'throwback', 'wistful', 'retro', 'antique', 'classic', 'golden days', 'vintage', 'heartwarming', 'timeless']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(choices_dict.keys())# will be dict keys\n",
    "counter = 0\n",
    "next_topic=None\n",
    "\n",
    "\n",
    "# iterate\n",
    "for x in data['SurveyElements']:\n",
    "    if type(x['Payload']) != dict:\n",
    "        continue\n",
    "    if 'QuestionType' not in x['Payload'].keys():\n",
    "        continue\n",
    "    if x['Payload']['QuestionType']=='MC': # group rank, influences others\n",
    "        text = topics[counter]\n",
    "        old_text = x['SecondaryAttribute']\n",
    "        new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "        x['Payload']['QuestionDescription']= new_q\n",
    "        x['SecondaryAttribute'] = new_q\n",
    "        x['Payload']['QuestionText']= new_q\n",
    "        choices = choices_dict[text]\n",
    "        new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "        x['Payload']['Choices']=new_choices\n",
    "        x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        counter +=1\n",
    "counter = 0\n",
    "for x in data['SurveyElements']:\n",
    "    if type(x['Payload']) != dict:\n",
    "        continue\n",
    "    if 'QuestionType' not in x['Payload'].keys():\n",
    "        continue\n",
    "    if x['Payload']['QuestionType']=='RO': # rank only, depends on other\n",
    "        # THIS COMES FIRST\n",
    "        # update Secondary Attribute: replace whatever is in \"\"\n",
    "        text = topics[counter]\n",
    "        next_topic = text\n",
    "        old_text = x['SecondaryAttribute']\n",
    "        new_q = f'Rank these quotes on how funny they are!'\n",
    "        x['SecondaryAttribute'] = new_q\n",
    "        # update ['Payload']['QuestionText'] replace whatever is in \"\"\n",
    "        x['Payload']['QuestionText']= new_q\n",
    "        x['Payload']['QuestionDescription']= new_q\n",
    "        counter+=1\n",
    "        #counter +=1\n",
    "\n",
    "# save\n",
    "with open('test.qsf', 'w') as json_file:\n",
    "    json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a function\n",
    "\n",
    "def new_survey_file(choices_dict:dict,file_name:str,template_name:str='Query_Template.qsf'):\n",
    "    with open(template_name, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    topics = list(choices_dict.keys())# will be dict keys\n",
    "    c_topics = topics.copy()\n",
    "    # surveyid = 'newstring'\n",
    "\n",
    "    # iterate\n",
    "    for x in data['SurveyElements']:\n",
    "        if type(x['Payload']) != dict:\n",
    "            continue\n",
    "        if 'QuestionType' not in x['Payload'].keys():\n",
    "            continue\n",
    "        # x['SurveyID']= surveyid\n",
    "        if x['Payload']['QuestionType']=='MC': # group rank, influences others\n",
    "            text = topics.pop()\n",
    "            new_q = f'Select whether or not the following quotes are similar to the query \"{text}\"'\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            choices = choices_dict[text]\n",
    "            new_choices = {str(x+1):{'Display': choices[x]} for x in range(len(choices))}\n",
    "            x['Payload']['Choices']=new_choices\n",
    "            x['Payload']['ChoiceOrder']=list(new_choices.keys())\n",
    "        if x['Payload']['QuestionType']=='RO': # rank only, depends on other\n",
    "            # update Secondary Attribute: replace whatever is in \"\"\n",
    "            text = c_topics.pop()\n",
    "            new_q = f'Rank these quotes on how funny they are!'\n",
    "            x['SecondaryAttribute'] = new_q\n",
    "            # update ['Payload']['QuestionText'] replace whatever is in \"\"\n",
    "            x['Payload']['QuestionText']= new_q\n",
    "            x['Payload']['QuestionDescription']= new_q\n",
    "\n",
    "    # save\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(data, json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up examples\n",
    "\n",
    "Now that I have the function written, I need to load up the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 0 documents. The engine now has 144211 documents.\n",
      "Complete data added.\n"
     ]
    }
   ],
   "source": [
    "# load up that search\n",
    "complete = pd.read_csv('https://scmcqueen.github.io/StarTrekScriptData/complete_data.csv')\n",
    "complete.columns = ['index','character', 'quote', 'scene', 'location', 'view',\n",
    "       'episode', 'date', 'series', 'file']\n",
    "complete['quote']=complete['quote'].apply(lambda text: \" \".join(text.split()))\n",
    "complete['character']=complete['character'].fillna('NA')\n",
    "test_engine = ss.search_engine()\n",
    "test_engine.bulk_load(complete[['quote']].to_dict()['quote'])\n",
    "test_engine.add_df(complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=test_engine.bw_search('candle',30)\n",
    "search_results = test_engine.pretty_print([x[0] for x in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [x[0] for x in results]\n",
    "choices = [' '.join(x) for x in search_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "choices = []\n",
    "search_term = []\n",
    "file_input = {}\n",
    "\n",
    "for term in keywords_1:\n",
    "    # do the search\n",
    "    results=test_engine.bw_search(term,20)\n",
    "    search_results = test_engine.pretty_print([x[0] for x in results])\n",
    "    # update values\n",
    "    t_ind = [x[0] for x in results]\n",
    "    t_choices = [' '.join(x) for x in search_results]\n",
    "    t_search = [term]*len(t_ind)\n",
    "    # update big list\n",
    "    indices+=t_ind\n",
    "    choices+=t_choices\n",
    "    search_term+=t_search\n",
    "    # update the dict\n",
    "    file_input[term] = t_choices\n",
    "\n",
    "new_survey_file(choices_dict=file_input,file_name='Evaluation/day_1.qsf',template_name='Query_Template.qsf')\n",
    "pd.DataFrame({'indices':indices,'choices':choices,'search':search_term}).to_csv('Evaluation/day_1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1 =  ['candle','dream','doctor','bajor','prophets','inequality','struggle','engineer','prune','humanity',\n",
    "               'story', 'religion', 'child', 'molly','counselor']\n",
    "keywords_2 =  ['archaeology','chateau','trial','fiction','romance','wedding','father','kahless','chocolate','future',\n",
    "               'bridge','saucer','coffee','romulans','colony']\n",
    "keywords_3 =  ['raktajino','commit no errors','tanagra','borg','cardassia','poetry','spot','assimilate','unusual','barclay',\n",
    "               'acquisition','rules','vedek','warp crystal',\"bat'leth\"]\n",
    "keywords_4 =  ['blood wine','gagh','cook','celebrate','impossible','earl grey','jake','geordi','riker','poker',\n",
    "               'phaser','occupation','conscious minds','tailor','neutral zone']\n",
    "keywords_5 =  ['men','women','miles','worf','bashir','commander','captain','kira','troi','guinan',\n",
    "               'shields','unification','mister spock','tribble','android']\n",
    "keywords_6 =  ['unraveled','friendship','hailing frequencies','universe','traveler','wesley','good tea','good book','make it so','flute',\n",
    "               'neutrino levels','noonian soong','breen','evidence','']\n",
    "keywords_7 =  ['memory','merry man','obedient','honor','san francisco','new orleans','liberation','imagination','maquis','tribunal',\n",
    "               'trill','lore','risa','detective','ezri']\n",
    "keywords_8 =  ['not picard','ice cream','morn','weyoun','dukat','civilization','replicators','truth','lunch','past',\n",
    "               'empath','betray','warp bubble','jadzia','pregnant']\n",
    "keywords_9 =  ['vineyard','lwaxana','bucket','justice is justice','espionage','same lie','mother','klingon','baseball','moriarty',\n",
    "               'vulcan','moon','lower decks','the academy','full impulse']\n",
    "keywords_10 =  ['enterprise','ferengi','nagus','death','rootbeer','alpha quadrant','wormhole','tasha','holosuite','holmes',\n",
    "                'the defiant','ensign ro','dabo girl','secret agent','oo-mox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {#1:keywords_1,\n",
    "            2:keywords_2,\n",
    "            3:keywords_3,\n",
    "            4:keywords_4,\n",
    "            5:keywords_5,\n",
    "            6:keywords_6,\n",
    "            7:keywords_7,\n",
    "            8:keywords_8,\n",
    "            9:keywords_9,\n",
    "            10:keywords_10\n",
    "            }\n",
    "\n",
    "for x in keywords.keys():\n",
    "    counter = str(x)\n",
    "    t_keys = keywords[x]\n",
    "\n",
    "    indices = []\n",
    "    choices = []\n",
    "    search_term = []\n",
    "    file_input = {}\n",
    "\n",
    "    for term in t_keys:\n",
    "        # do the search\n",
    "        results=test_engine.bw_search(term,20)\n",
    "        search_results = test_engine.pretty_print([x[0] for x in results])\n",
    "        # update values\n",
    "        t_ind = [x[0] for x in results]\n",
    "        t_choices = [' '.join(x) for x in search_results]\n",
    "        t_search = [term]*len(t_ind)\n",
    "        # update big list\n",
    "        indices+=t_ind\n",
    "        choices+=t_choices\n",
    "        search_term+=t_search\n",
    "        # update the dict\n",
    "        file_input[term] = t_choices\n",
    "\n",
    "    new_survey_file(choices_dict=file_input,file_name=f'Evaluation/day_{counter}.qsf',template_name='Query_Template.qsf')\n",
    "    pd.DataFrame({'indices':indices,'choices':choices,'search':search_term}).to_csv(f'Evaluation/day_{counter}_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si649f23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
