{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sentence Embeddings\n",
                "\n",
                "* get all sentence embeddings\n",
                "* train network/ fine tune roberta model\n",
                "* create a cheeky network!\n",
                "* PageRank?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting sentence_transformers\n",
                        "  Using cached sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
                        "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
                        "  Using cached transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
                        "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (4.67.1)\n",
                        "Collecting torch>=1.11.0 (from sentence_transformers)\n",
                        "  Downloading torch-2.6.0-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
                        "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (1.6.1)\n",
                        "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (1.15.2)\n",
                        "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
                        "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
                        "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (11.1.0)\n",
                        "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (4.13.0)\n",
                        "Collecting filelock (from huggingface-hub>=0.20.0->sentence_transformers)\n",
                        "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
                        "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in /Users/Skyeler/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0)\n",
                        "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
                        "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
                        "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
                        "Requirement already satisfied: jinja2 in /Users/Skyeler/Library/Python/3.11/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
                        "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
                        "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
                        "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence_transformers)\n",
                        "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
                        "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
                        "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
                        "  Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
                        "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
                        "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
                        "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
                        "Using cached sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
                        "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
                        "Downloading torch-2.6.0-cp311-none-macosx_11_0_arm64.whl (66.5 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
                        "Using cached transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
                        "Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hUsing cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
                        "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
                        "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
                        "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
                        "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: mpmath, sympy, safetensors, regex, networkx, filelock, torch, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
                        "Successfully installed filelock-3.18.0 huggingface-hub-0.30.2 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.5.3 sentence_transformers-4.0.2 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 transformers-4.51.1\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install sentence_transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "import pandas as pd\n",
                "import re\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[\"   You know, Morn -- there's nothing    quite as invigorating as breakfast    in a bar. Where else can you get    raw slug livers first thing in the    morning?\",\n",
                            " \"   What's this?\",\n",
                            " '   What do you mean, \"what\\'s this?\"    It\\'s puree of beetle.',\n",
                            " \"   I didn't order it.\",\n",
                            " '   Of course you \"didn\\'t order it\" --    you don\\'t need to order it. You    have it after work every morning.']"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# open dataframe\n",
                "complete = pd.read_csv('https://scmcqueen.github.io/StarTrekScriptData/complete_data.csv')\n",
                "\n",
                "# get sentences\n",
                "sentences = list(complete['quote'])\n",
                "\n",
                "# preview\n",
                "sentences[:5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cc22d64c1ffd47de8c36e7f124bb7378",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# load my girl roberta\n",
                "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# start by completing this problem on a mini model\n",
                "# baby = sentences[:100]\n",
                "# embeddings = model.encode(baby) # TBD later: embeddings = model.encode(sentences)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "embeddings = model.encode(sentences)\n",
                "# takes 4 minutes to run"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "embedding_df = pd.DataFrame(embeddings)\n",
                "# embedding_df.to_csv('st_embeddings.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Now that I have embeddings, I need to see if this will work with lambda rank"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DataTransformerRegistry.enable('default')"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import lightgbm as lgb\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
                "from sklearn.datasets import load_breast_cancer\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.compose import ColumnTransformer\n",
                "import nltk\n",
                "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
                "import spacy\n",
                "from spacy.tokens import Doc\n",
                "import csv\n",
                "import altair as alt\n",
                "\n",
                "alt.data_transformers.disable_max_rows()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>index</th>\n",
                            "      <th>query</th>\n",
                            "      <th>ranking</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>113689</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>113558</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>113532</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>55180</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>55060</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    index    query  ranking\n",
                            "0  113689  lwaxana       21\n",
                            "1  113558  lwaxana       21\n",
                            "2  113532  lwaxana       21\n",
                            "3   55180  lwaxana       21\n",
                            "4   55060  lwaxana       21"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# read in ratings\n",
                "ratings = pd.read_csv('skyeler_ranking_data.csv',index_col=0)\n",
                "ratings.drop(columns=['Unnamed: 0','quote'],inplace=True)\n",
                "ratings.columns=['index','query','ranking']\n",
                "ratings.ranking = ratings.ranking.apply(lambda z: ratings.ranking.max()+1 if z < 0 else z)\n",
                "ratings.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get index column for embeddings\n",
                "embedding_df=embedding_df.reset_index()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>index</th>\n",
                            "      <th>query</th>\n",
                            "      <th>ranking</th>\n",
                            "      <th>0</th>\n",
                            "      <th>1</th>\n",
                            "      <th>2</th>\n",
                            "      <th>3</th>\n",
                            "      <th>4</th>\n",
                            "      <th>5</th>\n",
                            "      <th>6</th>\n",
                            "      <th>...</th>\n",
                            "      <th>758</th>\n",
                            "      <th>759</th>\n",
                            "      <th>760</th>\n",
                            "      <th>761</th>\n",
                            "      <th>762</th>\n",
                            "      <th>763</th>\n",
                            "      <th>764</th>\n",
                            "      <th>765</th>\n",
                            "      <th>766</th>\n",
                            "      <th>767</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>113689</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0.018398</td>\n",
                            "      <td>0.012873</td>\n",
                            "      <td>-0.024242</td>\n",
                            "      <td>0.002963</td>\n",
                            "      <td>0.049414</td>\n",
                            "      <td>0.093950</td>\n",
                            "      <td>-0.004741</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.009880</td>\n",
                            "      <td>-0.042633</td>\n",
                            "      <td>-0.056167</td>\n",
                            "      <td>0.008068</td>\n",
                            "      <td>0.013000</td>\n",
                            "      <td>-0.046821</td>\n",
                            "      <td>0.00999</td>\n",
                            "      <td>0.005621</td>\n",
                            "      <td>0.028357</td>\n",
                            "      <td>0.019484</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>113558</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0.016721</td>\n",
                            "      <td>0.024398</td>\n",
                            "      <td>-0.030568</td>\n",
                            "      <td>-0.013274</td>\n",
                            "      <td>0.042874</td>\n",
                            "      <td>0.059577</td>\n",
                            "      <td>0.034213</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.011101</td>\n",
                            "      <td>-0.056366</td>\n",
                            "      <td>-0.052283</td>\n",
                            "      <td>0.000956</td>\n",
                            "      <td>0.000591</td>\n",
                            "      <td>-0.030117</td>\n",
                            "      <td>-0.00134</td>\n",
                            "      <td>0.000045</td>\n",
                            "      <td>0.005712</td>\n",
                            "      <td>0.018245</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>113532</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0.016721</td>\n",
                            "      <td>0.024398</td>\n",
                            "      <td>-0.030568</td>\n",
                            "      <td>-0.013274</td>\n",
                            "      <td>0.042874</td>\n",
                            "      <td>0.059577</td>\n",
                            "      <td>0.034213</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.011101</td>\n",
                            "      <td>-0.056366</td>\n",
                            "      <td>-0.052283</td>\n",
                            "      <td>0.000956</td>\n",
                            "      <td>0.000591</td>\n",
                            "      <td>-0.030117</td>\n",
                            "      <td>-0.00134</td>\n",
                            "      <td>0.000045</td>\n",
                            "      <td>0.005711</td>\n",
                            "      <td>0.018245</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>55180</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0.018398</td>\n",
                            "      <td>0.012873</td>\n",
                            "      <td>-0.024242</td>\n",
                            "      <td>0.002963</td>\n",
                            "      <td>0.049414</td>\n",
                            "      <td>0.093950</td>\n",
                            "      <td>-0.004741</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.009880</td>\n",
                            "      <td>-0.042633</td>\n",
                            "      <td>-0.056167</td>\n",
                            "      <td>0.008068</td>\n",
                            "      <td>0.013000</td>\n",
                            "      <td>-0.046821</td>\n",
                            "      <td>0.00999</td>\n",
                            "      <td>0.005621</td>\n",
                            "      <td>0.028357</td>\n",
                            "      <td>0.019484</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>55060</td>\n",
                            "      <td>lwaxana</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0.018398</td>\n",
                            "      <td>0.012873</td>\n",
                            "      <td>-0.024242</td>\n",
                            "      <td>0.002963</td>\n",
                            "      <td>0.049414</td>\n",
                            "      <td>0.093950</td>\n",
                            "      <td>-0.004741</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.009880</td>\n",
                            "      <td>-0.042633</td>\n",
                            "      <td>-0.056167</td>\n",
                            "      <td>0.008068</td>\n",
                            "      <td>0.013000</td>\n",
                            "      <td>-0.046821</td>\n",
                            "      <td>0.00999</td>\n",
                            "      <td>0.005621</td>\n",
                            "      <td>0.028357</td>\n",
                            "      <td>0.019484</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 771 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    index    query  ranking         0         1         2         3         4  \\\n",
                            "0  113689  lwaxana       21  0.018398  0.012873 -0.024242  0.002963  0.049414   \n",
                            "1  113558  lwaxana       21  0.016721  0.024398 -0.030568 -0.013274  0.042874   \n",
                            "2  113532  lwaxana       21  0.016721  0.024398 -0.030568 -0.013274  0.042874   \n",
                            "3   55180  lwaxana       21  0.018398  0.012873 -0.024242  0.002963  0.049414   \n",
                            "4   55060  lwaxana       21  0.018398  0.012873 -0.024242  0.002963  0.049414   \n",
                            "\n",
                            "          5         6  ...       758       759       760       761       762  \\\n",
                            "0  0.093950 -0.004741  ...  0.009880 -0.042633 -0.056167  0.008068  0.013000   \n",
                            "1  0.059577  0.034213  ...  0.011101 -0.056366 -0.052283  0.000956  0.000591   \n",
                            "2  0.059577  0.034213  ...  0.011101 -0.056366 -0.052283  0.000956  0.000591   \n",
                            "3  0.093950 -0.004741  ...  0.009880 -0.042633 -0.056167  0.008068  0.013000   \n",
                            "4  0.093950 -0.004741  ...  0.009880 -0.042633 -0.056167  0.008068  0.013000   \n",
                            "\n",
                            "        763      764       765       766       767  \n",
                            "0 -0.046821  0.00999  0.005621  0.028357  0.019484  \n",
                            "1 -0.030117 -0.00134  0.000045  0.005712  0.018245  \n",
                            "2 -0.030117 -0.00134  0.000045  0.005711  0.018245  \n",
                            "3 -0.046821  0.00999  0.005621  0.028357  0.019484  \n",
                            "4 -0.046821  0.00999  0.005621  0.028357  0.019484  \n",
                            "\n",
                            "[5 rows x 771 columns]"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# join the data\n",
                "ratings_embeddings = ratings.merge(embedding_df,on=['index'],how='left')\n",
                "ratings_embeddings.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train test split my data\n",
                "train, test = train_test_split(ratings_embeddings,test_size=.15,random_state=56)\n",
                "# sort my train values\n",
                "train = train.sort_values('query')\n",
                "test = test.sort_values('query')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_y = list(train['ranking'])\n",
                "train_groups = train['query'].value_counts().reset_index().sort_values('query')['count'].values\n",
                "train_X = train.drop(columns=['index','query','ranking'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_y = list(test['ranking'])\n",
                "test_groups = test['query'].value_counts().reset_index().sort_values('query')['count'].values\n",
                "test_X = test.drop(columns=['index','query','ranking'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_X is already prepared bc of the vectors!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data =lgb.Dataset(train_X, label=train_y, group=train_groups,params={'min_data_in_leaf':1})\n",
                "valid_data = lgb.Dataset(test_X,label=test_y,group=test_groups)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    'objective': 'lambdarank',\n",
                "    'metric': 'ndcg',\n",
                "    'learning_rate': 0.01,\n",
                "    'num_leaves': 19, # 31\n",
                "    'task':'train',\n",
                "    # 'feature_pre_filter':False,\n",
                "    \"num_leaves\": 255,\n",
                "    \"feature_pre_filter\": False,\n",
                "#   \"min_data_in_leaf\": 1,\n",
                "    'max_depth':40,\n",
                "    'verbose':-1\n",
                "    # 'max_depth':-1\n",
                "}\n",
                "res = {}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "ranker = lgb.train(params, train_data, num_boost_round=250,valid_sets=[valid_data])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "defaultdict(collections.OrderedDict,\n",
                            "            {'valid_0': OrderedDict([('ndcg@1', 0.8278325829572262),\n",
                            "                          ('ndcg@2', 0.8748111947107955),\n",
                            "                          ('ndcg@3', 0.9000711937286457),\n",
                            "                          ('ndcg@4', 0.9101365714504701),\n",
                            "                          ('ndcg@5', 0.9225574551310549)])})"
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ranker.best_score"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}